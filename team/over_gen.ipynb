{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf5997d4-f8c4-494f-a063-867daf6076a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/project/team/code\n"
     ]
    }
   ],
   "source": [
    "%cd /opt/ml/project/team/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a454ed7c-b5b3-4936-877d-41bf3b3da5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "from attrdict import AttrDict\n",
    "import sys\n",
    "from torch.functional import split\n",
    "import yaml\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from torch.cuda.amp import autocast\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "from prepare import get_data, get_stuff, get_model\n",
    "import parser_maker\n",
    "from data_utils import split_slot, convert_state_dict, WOSDataset\n",
    "\n",
    "from training_recorder import RunningLossRecorder\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Union\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8097d13a-1bef-4782-8b6a-b62d6a7a353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_dir = '/opt/ml/project/team/code/results/random_1125_1'\n",
    "\n",
    "root_name = '/opt/ml/input/data/tmp/'\n",
    "files = glob.glob(f'{root_name}/need_overgen*')\n",
    "output_dir = '/opt/ml/input/data/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d405896-2c94-4730-85b4-c5fb73b92ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using train: train_dials.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63951b57d5f4067a8deae6d6345e566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Making TRADE model -- waiting...', max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# conf=dict()\n",
    "# with open(config_root) as f:\n",
    "#     conf = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "# eval_data = json.load(open(f\"/opt/ml/input/data/eval_dataset/eval_dials.json\", \"r\"))\n",
    "\n",
    "config = json.load(open(f\"{task_dir}/exp_config.json\", \"r\"))\n",
    "\n",
    "# print(config)\n",
    "config = argparse.Namespace(**config)\n",
    "_, slot_meta, ontology = get_data(config)\n",
    "\n",
    "config.device = device\n",
    "\n",
    "config.use_cache_examples2features = False\n",
    "tokenizer, processor, _, _ = get_stuff(config,\n",
    "             None, None, slot_meta, ontology)\n",
    "\n",
    "# eval_data = WOSDataset(eval_features)\n",
    "# eval_sampler = SequentialSampler(eval_data)\n",
    "# eval_loader = DataLoader(\n",
    "#     eval_data,\n",
    "#     batch_size=8,\n",
    "#     sampler=eval_sampler,\n",
    "#     collate_fn=processor.collate_fn,\n",
    "# )\n",
    "# print(\"# eval:\", len(eval_data))\n",
    "\n",
    "# print(slot_meta)\n",
    "\n",
    "model =  get_model(config, tokenizer, ontology, slot_meta)\n",
    "\n",
    "\n",
    "ckpt = torch.load(f\"{task_dir}/model-best.bin\", map_location=\"cpu\")\n",
    "# ckpt = torch.load(\"/opt/ml/gyujins_file/model-best.bin\", map_location=\"cpu\")\n",
    "\n",
    "model.load_state_dict(ckpt)\n",
    "model.to(device)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e56380bc-c650-488e-9db0-06c9814d9fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "for file in files:\n",
    "#     print(file)\n",
    "    cur_batch = pickle.load(open(file, 'rb'))\n",
    "#     print(cur_batch[0])\n",
    "    data.extend(cur_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb33b29d-322e-4f11-b9d1-764fe0d6dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@dataclass\n",
    "class DSTInputExample:\n",
    "    guid: str\n",
    "    context_turns: List[str]\n",
    "    current_turn: List[str]\n",
    "    label: Optional[List[str]] = None\n",
    "    before_label: Optional[List[str]] = None\n",
    "\n",
    "    def to_dict(self):\n",
    "        return dataclasses.asdict(self)\n",
    "\n",
    "    def to_json_string(self):\n",
    "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
    "        return json.dumps(self.to_dict(), indent=2) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ebcc4e-fa12-4cf1-9833-aa41a3a65fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_state(state):\n",
    "    for i, s in enumerate(state):\n",
    "        s = s.replace(\" : \", \":\")\n",
    "        s = s.replace(\" & \", \"&\")\n",
    "        s = s.replace(\" = \", \"=\")\n",
    "        s = s.replace(\"( \", \"(\")\n",
    "        s = s.replace(\" )\", \")\")\n",
    "        state[i] = s.replace(\" , \", \", \")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddba9183-2ad1-44e4-bba7-2c87984bba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "for idx, datum in enumerate(data):\n",
    "    examples.append(\n",
    "            DSTInputExample(\n",
    "                guid=f\"{datum.guid}-{datum.turn}\",\n",
    "                context_turns=[\"\", \"\"],\n",
    "                current_turn=[datum.sys, datum.text],  # TRADE,SUMBT 다름 유의\n",
    "                label=datum.state, \n",
    "                before_label={}, # This was for som_dst\n",
    "            )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d99af5-8975-4870-aae7-e30920d138cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326de8b137cb4cdb866bb46d793cdefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Converting  examples to features', max=7383.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = processor.convert_examples_to_features(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a556af94-bbfd-4ece-99ad-591508b3519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = WOSDataset(features)\n",
    "sampler = SequentialSampler(ds)\n",
    "eval_loader = DataLoader(\n",
    "    ds,\n",
    "    batch_size=8,\n",
    "    sampler=sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42fa1754-e549-45e3-888e-3bd23fafa5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, torch.int64, torch.bool)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape, segment_ids.shape, input_masks.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcbe394-6165-4c22-abe8-c195c8bba356",
   "metadata": {},
   "outputs": [],
   "source": [
    "gating_ids.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3c6e5d9-fdd1-49f5-9153-56b556ba6b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d708c2f0f64cf0a7588593d1ae34e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=923.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 68])\n",
      "torch.Size([8, 64])\n",
      "torch.Size([8, 66])\n",
      "torch.Size([8, 59])\n",
      "torch.Size([8, 109])\n",
      "torch.Size([8, 69])\n",
      "torch.Size([8, 49])\n",
      "torch.Size([8, 54])\n",
      "torch.Size([8, 86])\n",
      "torch.Size([8, 46])\n",
      "torch.Size([8, 72])\n",
      "torch.Size([8, 69])\n",
      "torch.Size([8, 81])\n",
      "torch.Size([8, 53])\n",
      "torch.Size([8, 58])\n",
      "torch.Size([8, 90])\n",
      "torch.Size([8, 68])\n",
      "torch.Size([8, 91])\n",
      "torch.Size([8, 54])\n",
      "torch.Size([8, 64])\n",
      "torch.Size([8, 78])\n",
      "torch.Size([8, 79])\n",
      "torch.Size([8, 74])\n",
      "torch.Size([8, 84])\n",
      "torch.Size([8, 65])\n",
      "torch.Size([8, 80])\n",
      "torch.Size([8, 67])\n",
      "torch.Size([8, 76])\n",
      "torch.Size([8, 72])\n",
      "torch.Size([8, 69])\n",
      "torch.Size([8, 58])\n",
      "torch.Size([8, 68])\n",
      "torch.Size([8, 120])\n",
      "torch.Size([8, 118])\n",
      "torch.Size([8, 87])\n",
      "torch.Size([8, 104])\n",
      "torch.Size([8, 100])\n",
      "torch.Size([8, 70])\n",
      "torch.Size([8, 92])\n",
      "torch.Size([8, 47])\n",
      "torch.Size([8, 82])\n",
      "torch.Size([8, 74])\n",
      "torch.Size([8, 63])\n",
      "torch.Size([8, 74])\n",
      "torch.Size([8, 70])\n",
      "torch.Size([8, 50])\n",
      "torch.Size([8, 75])\n",
      "torch.Size([8, 59])\n",
      "torch.Size([8, 58])\n",
      "torch.Size([8, 63])\n",
      "torch.Size([8, 87])\n",
      "torch.Size([8, 93])\n",
      "torch.Size([8, 105])\n",
      "torch.Size([8, 64])\n",
      "torch.Size([8, 70])\n",
      "torch.Size([8, 62])\n",
      "torch.Size([8, 72])\n",
      "torch.Size([8, 68])\n",
      "torch.Size([8, 66])\n",
      "torch.Size([8, 95])\n",
      "torch.Size([8, 53])\n",
      "torch.Size([8, 66])\n",
      "torch.Size([8, 62])\n",
      "torch.Size([8, 77])\n",
      "torch.Size([8, 62])\n",
      "torch.Size([8, 52])\n",
      "torch.Size([8, 67])\n",
      "torch.Size([8, 83])\n",
      "torch.Size([8, 87])\n",
      "torch.Size([8, 61])\n",
      "torch.Size([8, 81])\n",
      "torch.Size([8, 88])\n",
      "torch.Size([8, 64])\n",
      "torch.Size([8, 68])\n",
      "torch.Size([8, 74])\n",
      "torch.Size([8, 61])\n",
      "torch.Size([8, 74])\n",
      "torch.Size([8, 61])\n",
      "torch.Size([8, 75])\n",
      "torch.Size([8, 56])\n",
      "torch.Size([8, 50])\n",
      "torch.Size([8, 62])\n",
      "torch.Size([8, 69])\n",
      "torch.Size([8, 60])\n",
      "torch.Size([8, 74])\n",
      "torch.Size([8, 63])\n",
      "torch.Size([8, 63])\n",
      "torch.Size([8, 76])\n",
      "torch.Size([8, 75])\n",
      "torch.Size([8, 69])\n",
      "torch.Size([8, 71])\n",
      "torch.Size([8, 101])\n",
      "torch.Size([8, 63])\n",
      "torch.Size([8, 59])\n",
      "torch.Size([8, 70])\n",
      "torch.Size([8, 55])\n",
      "torch.Size([8, 69])\n",
      "torch.Size([8, 64])\n",
      "torch.Size([8, 76])\n",
      "torch.Size([8, 70])\n",
      "torch.Size([8, 63])\n",
      "torch.Size([8, 73])\n",
      "torch.Size([8, 52])\n",
      "torch.Size([8, 66])\n",
      "torch.Size([8, 95])\n",
      "torch.Size([8, 55])\n",
      "torch.Size([8, 67])\n",
      "torch.Size([8, 70])\n",
      "torch.Size([8, 67])\n",
      "torch.Size([8, 78])\n",
      "torch.Size([8, 92])\n",
      "torch.Size([8, 66])\n",
      "torch.Size([8, 77])\n",
      "torch.Size([8, 99])\n",
      "torch.Size([8, 58])\n",
      "torch.Size([8, 66])\n",
      "torch.Size([8, 59])\n",
      "torch.Size([8, 60])\n",
      "torch.Size([8, 73])\n",
      "torch.Size([8, 51])\n",
      "torch.Size([8, 74])\n",
      "torch.Size([8, 84])\n",
      "torch.Size([8, 70])\n",
      "torch.Size([8, 65])\n",
      "torch.Size([8, 103])\n",
      "torch.Size([8, 55])\n",
      "torch.Size([8, 59])\n",
      "torch.Size([8, 59])\n",
      "torch.Size([8, 58])\n",
      "torch.Size([8, 69])\n",
      "torch.Size([8, 51])\n",
      "torch.Size([8, 67])\n",
      "torch.Size([8, 51])\n",
      "torch.Size([8, 74])\n",
      "torch.Size([8, 55])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 76])\n",
      "torch.Size([8, 60])\n",
      "torch.Size([8, 72])\n",
      "torch.Size([8, 55])\n",
      "torch.Size([8, 65])\n",
      "torch.Size([8, 68])\n",
      "torch.Size([8, 76])\n",
      "torch.Size([8, 76])\n",
      "torch.Size([8, 88])\n",
      "torch.Size([8, 48])\n",
      "torch.Size([8, 77])\n",
      "torch.Size([8, 51])\n",
      "torch.Size([8, 101])\n",
      "torch.Size([8, 65])\n",
      "torch.Size([8, 77])\n",
      "torch.Size([8, 94])\n",
      "torch.Size([8, 88])\n",
      "torch.Size([8, 66])\n",
      "torch.Size([8, 86])\n",
      "torch.Size([8, 49])\n",
      "torch.Size([8, 78])\n",
      "torch.Size([8, 79])\n",
      "torch.Size([8, 49])\n",
      "torch.Size([8, 76])\n",
      "torch.Size([8, 64])\n",
      "torch.Size([8, 79])\n",
      "torch.Size([8, 53])\n",
      "torch.Size([8, 63])\n",
      "torch.Size([8, 67])\n",
      "torch.Size([8, 57])\n",
      "torch.Size([8, 106])\n",
      "torch.Size([8, 59])\n",
      "torch.Size([8, 64])\n",
      "torch.Size([8, 65])\n",
      "torch.Size([8, 71])\n",
      "torch.Size([8, 59])\n",
      "torch.Size([8, 65])\n",
      "torch.Size([8, 82])\n",
      "torch.Size([8, 76])\n",
      "torch.Size([8, 66])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d33fb37f5c15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_amp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/team/code/model/trade.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, max_len, teacher)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         all_point_outputs, all_gate_outputs = self.decoder(\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         )\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/team/code/model/trade.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, encoder_output, hidden, input_masks, max_len, teacher)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_decoder_ts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mw_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# B, D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                 \u001b[0;31m# hidden, state = self.decoder(w, encoder_output, len_mask, state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/fast_transformers/recurrent/transformers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, memory, memory_length_mask, state)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             x, s = layer(x, memory, memory_length_mask=memory_length_mask,\n\u001b[0;32m--> 272\u001b[0;31m                          state=state[i])\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/fast_transformers/recurrent/transformers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, memory, memory_length_mask, state)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mmemory_length_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory_length_mask\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mLengthMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;31m# Extract the individual states for the self attention and the cross\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/fast_transformers/masking.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lengths, max_len, device)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bool_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_ones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lengths\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "use_amp = False\n",
    "\n",
    "model.eval()\n",
    "predictions = {}\n",
    "pbar = tqdm(eval_loader, total=len(eval_loader), file=sys.stdout)\n",
    "\n",
    "for batch in pbar:\n",
    "    input_ids, segment_ids, input_masks, gating_ids, target_ids, guids = [\n",
    "        b.to(device) if not isinstance(b, list) else b for b in batch\n",
    "    ]\n",
    "#     print(input_ids.shape)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with autocast(enabled=use_amp):\n",
    "            o, g = model(input_ids, segment_ids, input_masks, 9)\n",
    "\n",
    "        _, generated_ids = o.max(-1)\n",
    "        _, gated_ids = g.max(-1)\n",
    "\n",
    "\n",
    "    for guid, gate, gen in zip(guids, gated_ids.tolist(), generated_ids.tolist()):\n",
    "        prediction = processor.recover_state(gate, gen)\n",
    "        prediction = postprocess_state(prediction)\n",
    "        predictions[guid] = prediction\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd2242-b68c-4a0b-a4de-a79fe35350a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a76fc3c-59b3-4c8d-8f16-c112a75e4ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "good = []\n",
    "bad = []\n",
    "good_idxs = []\n",
    "for i, example in enumerate(examples):\n",
    "    assert example.guid == f'{data[i].guid}-{data[i].turn}'\n",
    "    guid = example.guid\n",
    "\n",
    "    answer = convert_state_dict(example.label)\n",
    "    pred = convert_state_dict(predictions[guid])\n",
    "    if set(pred).issubset(set(answer)):\n",
    "        good_idxs.append(i)\n",
    "        good.append(\n",
    "            AttrDict(\n",
    "                example=example,\n",
    "                prediction=predictions[guid],\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        bad.append(\n",
    "            AttrDict(\n",
    "                example=example,\n",
    "                prediction=predictions[guid],\n",
    "            )\n",
    "        )\n",
    "    \n",
    "len(good), len(bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c23e4a1-9e6d-4054-b5e2-10efc0d73623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc84843-8b6f-4b59-a6eb-759a043f4372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a93dc-0f1b-40ae-83d6-fedea3bbb42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e8d4f9-ee91-4051-adf9-31f08f6af1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c896827-38e5-480f-851d-44072e63e9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e645ad-13e4-4bd6-be96-4fd5186aa0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'SYS: {bad[idx].example.current_turn[0]}')\n",
    "print(f'USR: {bad[idx].example.current_turn[1]}')\n",
    "print(f' ANS: {sorted(bad[idx].example.label)}')\n",
    "print(f'PRED: {sorted(bad[idx].prediction)}')\n",
    "print(bad[idx].example.guid)\n",
    "idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6af83f-b389-421b-a236-1ef034215a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841a6de-4ca2-48b8-8195-1ccb4501bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'SYS: {good[idx].example.current_turn[0]}')\n",
    "print(f'USR: {good[idx].example.current_turn[1]}')\n",
    "print(f' ANS: {sorted(good[idx].example.label)}')\n",
    "print(f'PRED: {sorted(good[idx].prediction)}')\n",
    "idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a635d0-9e29-443a-9710-e452daf90016",
   "metadata": {},
   "outputs": [],
   "source": [
    "good[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceebfae7-c8f8-4e11-96a3-395518256ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_good = []\n",
    "# for x in good:\n",
    "#     if set(x.example.label) != set(x.prediction):\n",
    "#         diff_good.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f7f82-75b7-44ce-bfb5-aff7ae6c81b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528b1394-13f4-4991-9e63-db579de5ab20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39758874-bfa6-4da6-8a46-82cfc6f37b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f36beb-3c19-44d7-b7f3-863622020dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b283ee18-0348-4947-93a3-ebdc9eb9d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_good = []\n",
    "diff_idxs = []\n",
    "for i, x in enumerate(good):\n",
    "    if set(x.example.label) != set(x.prediction):\n",
    "        diff_good.append(x)\n",
    "        diff_idxs.append(good_idxs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9022d-cd31-4d6b-96a6-2ea0e431c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, diff_idx in enumerate(diff_idxs):\n",
    "    assert diff_good[i].example.guid == f'{data[diff_idx].guid}-{data[diff_idx].turn}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a040331-69ac-4bb5-bb14-1a9040c033bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "saving = defaultdict(list)\n",
    "for diff_idx in diff_idxs:\n",
    "    datum = data[diff_idx]\n",
    "    turn_stuff = {\n",
    "        'text':datum.text,\n",
    "        'state':list(datum.state),\n",
    "    }\n",
    "    \n",
    "    guid_stuff = {\n",
    "        datum.turn: turn_stuff\n",
    "    }\n",
    "    \n",
    "    saving[datum.guid].append(\n",
    "        guid_stuff\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a018d8-419a-46eb-bcb6-951049d43f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "while True:\n",
    "    name = f'{output_dir}/final_{idx}.pkl'\n",
    "    if not os.path.exists(name):\n",
    "        break\n",
    "    idx += 1\n",
    "\n",
    "name = f'{output_dir}/final_size_{len(diff_idxs)}_{idx}.pkl' \n",
    "pickle.dump(saving, open(name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a27e9-0577-420b-9197-418a130975e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa976ec2-0842-4e53-974d-755e5c919108",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c383035-1318-4aff-9d0d-422dd8dee17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'SYS: {diff_good[idx].example.current_turn[0]}')\n",
    "print(f'USR: {diff_good[idx].example.current_turn[1]}')\n",
    "print(f' ANS: {sorted(diff_good[idx].example.label)}')\n",
    "print(f'PRED: {sorted(diff_good[idx].prediction)}')\n",
    "idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b4dbc7-ae99-4f11-9aea-e2cbb5c1c488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c25dc99-c510-4dea-9908-b735863266a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
