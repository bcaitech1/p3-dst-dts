{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Koaz3guQ6B7k",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from data_utils import get_examples_from_dialogues, convert_state_dict, load_dataset\n",
    "from data_utils import OntologyDSTFeature, DSTPreprocessor, _truncate_seq_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCYa_jbt6B7m"
   },
   "source": [
    "## Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "y2Jpgv4i6B7n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_file = \"/opt/ml/input/data/train_dataset/train_dials.json\"\n",
    "slot_meta = json.load(open(\"/opt/ml/input/data/train_dataset/slot_meta.json\"))\n",
    "ontology = json.load(open(\"/opt/ml/input/data/train_dataset/ontology.json\"))\n",
    "train_data, dev_data, dev_labels = load_dataset(train_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Vu232Prn6B7n",
    "outputId": "a17014f7-81fd-41c6-c4e6-c4958942a45e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6301/6301 [00:00<00:00, 9090.04it/s]\n",
      "100%|██████████| 699/699 [00:00<00:00, 15785.55it/s]\n"
     ]
    }
   ],
   "source": [
    "train_examples = get_examples_from_dialogues(data=train_data,\n",
    "                                             user_first=True,\n",
    "                                             dialogue_level=True)\n",
    "\n",
    "dev_examples = get_examples_from_dialogues(data=dev_data,\n",
    "                                           user_first=True,\n",
    "                                           dialogue_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aGKZk4_n6B7o",
    "outputId": "5502faa6-a80f-496a-fe8f-399ecd62350f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6301"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1qqe5Hw36B7o",
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_turn = max([len(e['dialogue']) for e in train_data])\n",
    "tokenizer = BertTokenizer.from_pretrained('dsksd/bert-ko-small-minimal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kq2fddAg6B7p"
   },
   "source": [
    "## TODO-1: SUMBT Preprocessor 정의 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCoRCk1z6B7p"
   },
   "source": [
    "Ontology-based DST model인 SUMBT의 InputFeature를 만들기 위한 Preprocessor를 정의해야 합니다. <br>\n",
    "\n",
    "1. `_convert_examples_to_features` 함수의 빈칸을 매워 완성하세요.\n",
    "2. `recover_state` 함수의 빈칸을 매워 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "p8MjYjqw6B7p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SUMBTPreprocessor(DSTPreprocessor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        slot_meta,\n",
    "        src_tokenizer,\n",
    "        trg_tokenizer=None,\n",
    "        ontology=None,\n",
    "        max_seq_length=64,\n",
    "        max_turn_length=14,\n",
    "    ):\n",
    "        self.slot_meta = slot_meta\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.trg_tokenizer = trg_tokenizer if trg_tokenizer else src_tokenizer\n",
    "        self.ontology = ontology\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.max_turn_length = max_turn_length\n",
    "\n",
    "    def _convert_example_to_feature(self, example):\n",
    "        guid = example[0].guid.rsplit(\"-\", 1)[0]  # dialogue_idx\n",
    "        turns = []\n",
    "        token_types = []\n",
    "        labels = []\n",
    "        num_turn = None\n",
    "        for turn in example[: self.max_turn_length]:\n",
    "            assert len(turn.current_turn) == 2\n",
    "            uttrs = []\n",
    "            for segment_idx, uttr in enumerate(turn.current_turn):\n",
    "                token = self.src_tokenizer.encode(uttr, add_special_tokens=False)\n",
    "                uttrs.append(token)\n",
    "\n",
    "            _truncate_seq_pair(uttrs[0], uttrs[1], self.max_seq_length - 3)\n",
    "            tokens = (\n",
    "                [self.src_tokenizer.cls_token_id]\n",
    "                + uttrs[0]\n",
    "                + [self.src_tokenizer.sep_token_id]\n",
    "                + uttrs[1]\n",
    "                + [self.src_tokenizer.sep_token_id]\n",
    "            )\n",
    "            token_type = [0] * (len(uttrs[0]) + 2) + [1] * (len(uttrs[1]) + 1)\n",
    "            if len(tokens) < self.max_seq_length:\n",
    "                gap = self.max_seq_length - len(tokens)\n",
    "                tokens.extend([self.src_tokenizer.pad_token_id] * gap)\n",
    "                token_type.extend([0] * gap)\n",
    "            turns.append(tokens)\n",
    "            token_types.append(token_type)\n",
    "            label = []\n",
    "            if turn.label:\n",
    "                slot_dict = convert_state_dict(turn.label)\n",
    "            else:\n",
    "                slot_dict = {}\n",
    "            for slot_type in self.slot_meta:\n",
    "                value = slot_dict.get(slot_type, \"none\")\n",
    "                # TODO\n",
    "#                 raise Exception('label_idx를 ontology에서 꺼내오는 코드를 작성하세요!')\n",
    "                # Your code here!\n",
    "                if value in self.ontology[slot_type]:\n",
    "                    label_idx = self.ontology[slot_type].index(value)\n",
    "                else:\n",
    "                    label_idx = self.ontology[slot_type].index(\"none\")\n",
    "                # Your code here!\n",
    "                label.append(label_idx)\n",
    "            labels.append(label)\n",
    "        num_turn = len(turns)\n",
    "        if len(turns) < self.max_turn_length:\n",
    "            gap = self.max_turn_length - len(turns)\n",
    "            for _ in range(gap):\n",
    "                dummy_turn = [self.src_tokenizer.pad_token_id] * self.max_seq_length\n",
    "                turns.append(dummy_turn)\n",
    "                token_types.append(dummy_turn)\n",
    "                dummy_label = [-1] * len(self.slot_meta)\n",
    "                labels.append(dummy_label)\n",
    "        return OntologyDSTFeature(\n",
    "            guid=guid,\n",
    "            input_ids=turns,\n",
    "            segment_ids=token_types,\n",
    "            num_turn=num_turn,\n",
    "            target_ids=labels,\n",
    "        )\n",
    "\n",
    "    def convert_examples_to_features(self, examples):\n",
    "        return list(map(self._convert_example_to_feature, examples))\n",
    "\n",
    "    def recover_state(self, pred_slots, num_turn):\n",
    "        states = []\n",
    "        # TODO\n",
    "#         raise Exception('SUMBT의 아웃풋을 prediction form으로 바꾸는 코드를 작성하세요!')\n",
    "        # Your code here!\n",
    "#         for pred_slot in pred_slots[:num_turn]:\n",
    "#             state=[]\n",
    "#             for key,val_idx in zip(self.slot_meta,pred_slot):\n",
    "#                 val=self.ontology[key][val_idx]\n",
    "#                 if val==0:\n",
    "#                     continue\n",
    "#                 state.append(f'{key}-{val}')\n",
    "#             states.append(state)\n",
    "#         # Your code here!\n",
    "#         return states\n",
    "        for pred_slot in pred_slots[:num_turn]:\n",
    "            state = []\n",
    "            for s, p in zip(self.slot_meta, pred_slot):\n",
    "                v = self.ontology[s][p]\n",
    "                if v != \"none\":\n",
    "                    state.append(f\"{s}-{v}\")\n",
    "            states.append(state)\n",
    "        return states\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        guids = [b.guid for b in batch]\n",
    "        input_ids = torch.LongTensor([b.input_ids for b in batch])\n",
    "        segment_ids = torch.LongTensor([b.segment_ids for b in batch])\n",
    "        input_masks = input_ids.ne(self.src_tokenizer.pad_token_id)\n",
    "        target_ids = torch.LongTensor([b.target_ids for b in batch])\n",
    "        num_turns = [b.num_turn for b in batch]\n",
    "        return input_ids, segment_ids, input_masks, target_ids, num_turns, guids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhFMIiFy6B7q"
   },
   "source": [
    "## Convert_Examples_to_Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EKluwCmH6B7r",
    "tags": []
   },
   "outputs": [],
   "source": [
    "processor = SUMBTPreprocessor(slot_meta,\n",
    "                              tokenizer,\n",
    "                              ontology=ontology,  # predefined ontology\n",
    "                              max_seq_length=128,  # 각 turn마다 최대 길이\n",
    "                              max_turn_length=max_turn)  # 각 dialogue의 최대 turn 길이\n",
    "train_features = processor.convert_examples_to_features(train_examples)\n",
    "dev_features = processor.convert_examples_to_features(dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zrIVLPMd6B7r",
    "outputId": "e2b46db4-4bc0-48b2-b23b-577fe3678543",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6301\n",
      "699\n"
     ]
    }
   ],
   "source": [
    "print(len(train_features))  # 대화 level의 features\n",
    "print(len(dev_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a3j7tb96B7r"
   },
   "source": [
    "## SUMBT 모델 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-IjCE6Db6B7r",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Most of code is from https://github.com/SKTBrain/SUMBT\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CosineEmbeddingLoss, CrossEntropyLoss\n",
    "from transformers import BertModel, BertPreTrainedModel\n",
    "\n",
    "\n",
    "class BertForUtteranceEncoding(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertForUtteranceEncoding, self).__init__(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.bert = BertModel(config)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
    "        return self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False,\n",
    "            return_dict=False,\n",
    "        )\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.scores = None\n",
    "\n",
    "    def attention(self, q, k, v, d_k, mask=None, dropout=None):\n",
    "\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = F.softmax(scores, dim=-1)\n",
    "\n",
    "        if dropout is not None:\n",
    "            scores = dropout(scores)\n",
    "\n",
    "        self.scores = scores\n",
    "        output = torch.matmul(scores, v)\n",
    "        return output\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        bs = q.size(0)\n",
    "\n",
    "        # perform linear operation and split into h heads\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "\n",
    "        # transpose to get dimensions bs * h * sl * d_model\n",
    "        k = k.transpose(1, 2)\n",
    "        q = q.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        scores = self.attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "\n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n",
    "        output = self.out(concat)\n",
    "        return output\n",
    "\n",
    "    def get_scores(self):\n",
    "        return self.scores\n",
    "\n",
    "\n",
    "class SUMBT(nn.Module):\n",
    "    def __init__(self, args, num_labels, device):\n",
    "        super(SUMBT, self).__init__()\n",
    "\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.rnn_num_layers = args.num_rnn_layers\n",
    "        self.zero_init_rnn = args.zero_init_rnn\n",
    "        self.max_seq_length = args.max_seq_length\n",
    "        self.max_label_length = args.max_label_length\n",
    "        self.num_labels = num_labels\n",
    "        self.num_slots = len(num_labels)\n",
    "        self.attn_head = args.attn_head\n",
    "        self.device = device\n",
    "\n",
    "        ### Utterance Encoder\n",
    "        self.utterance_encoder = BertForUtteranceEncoding.from_pretrained(\n",
    "            args.model_name_or_path\n",
    "        )\n",
    "        self.bert_output_dim = self.utterance_encoder.config.hidden_size\n",
    "        self.hidden_dropout_prob = self.utterance_encoder.config.hidden_dropout_prob\n",
    "        if args.fix_utterance_encoder:\n",
    "            for p in self.utterance_encoder.bert.pooler.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        ### slot, slot-value Encoder (not trainable)\n",
    "        self.sv_encoder = BertForUtteranceEncoding.from_pretrained(\n",
    "            args.model_name_or_path\n",
    "        )\n",
    "        # os.path.join(args.bert_dir, 'bert-base-uncased.model'))\n",
    "        for p in self.sv_encoder.bert.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.slot_lookup = nn.Embedding(self.num_slots, self.bert_output_dim)\n",
    "        self.value_lookup = nn.ModuleList(\n",
    "            [nn.Embedding(num_label, self.bert_output_dim) for num_label in num_labels]\n",
    "        )\n",
    "\n",
    "        ### Attention layer\n",
    "        self.attn = MultiHeadAttention(self.attn_head, self.bert_output_dim, dropout=0)\n",
    "\n",
    "        ### RNN Belief Tracker\n",
    "        self.nbt = nn.GRU(\n",
    "            input_size=self.bert_output_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.rnn_num_layers,\n",
    "            dropout=self.hidden_dropout_prob,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.init_parameter(self.nbt)\n",
    "\n",
    "        if not self.zero_init_rnn:\n",
    "            self.rnn_init_linear = nn.Sequential(\n",
    "                nn.Linear(self.bert_output_dim, self.hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.hidden_dropout_prob),\n",
    "            )\n",
    "\n",
    "        self.linear = nn.Linear(self.hidden_dim, self.bert_output_dim)\n",
    "        self.layer_norm = nn.LayerNorm(self.bert_output_dim)\n",
    "\n",
    "        ### Measure\n",
    "        self.metric = torch.nn.PairwiseDistance(p=2.0, eps=1e-06, keepdim=False)\n",
    "\n",
    "        ### Classifier\n",
    "        self.nll = CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "        ### Etc.\n",
    "        self.dropout = nn.Dropout(self.hidden_dropout_prob)\n",
    "\n",
    "    def initialize_slot_value_lookup(self, label_ids, slot_ids):\n",
    "\n",
    "        self.sv_encoder.eval()\n",
    "\n",
    "        # Slot encoding\n",
    "        slot_type_ids = torch.zeros(slot_ids.size(), dtype=torch.long).to(\n",
    "            slot_ids.device\n",
    "        )\n",
    "        slot_mask = slot_ids > 0\n",
    "        hid_slot, _ = self.sv_encoder(\n",
    "            slot_ids.view(-1, self.max_label_length),\n",
    "            slot_type_ids.view(-1, self.max_label_length),\n",
    "            slot_mask.view(-1, self.max_label_length),\n",
    "        )\n",
    "        hid_slot = hid_slot[:, 0, :]\n",
    "        hid_slot = hid_slot.detach()\n",
    "        self.slot_lookup = nn.Embedding.from_pretrained(hid_slot, freeze=True)\n",
    "\n",
    "        for s, label_id in enumerate(label_ids):\n",
    "            label_type_ids = torch.zeros(label_id.size(), dtype=torch.long).to(\n",
    "                label_id.device\n",
    "            )\n",
    "            label_mask = label_id > 0\n",
    "            hid_label, _ = self.sv_encoder(\n",
    "                label_id.view(-1, self.max_label_length),\n",
    "                label_type_ids.view(-1, self.max_label_length),\n",
    "                label_mask.view(-1, self.max_label_length),\n",
    "            )\n",
    "            hid_label = hid_label[:, 0, :]\n",
    "            hid_label = hid_label.detach()\n",
    "            self.value_lookup[s] = nn.Embedding.from_pretrained(hid_label, freeze=True)\n",
    "            self.value_lookup[s].padding_idx = -1\n",
    "\n",
    "        print(\"Complete initialization of slot and value lookup\")\n",
    "        self.sv_encoder = None\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        token_type_ids,\n",
    "        attention_mask,\n",
    "        labels=None,\n",
    "        n_gpu=1,\n",
    "        target_slot=None,\n",
    "    ):\n",
    "        # input_ids: [B, M, N]\n",
    "        # token_type_ids: [B, M, N]\n",
    "        # attention_mask: [B, M, N]\n",
    "        # labels: [B, M, J]\n",
    "\n",
    "        # if target_slot is not specified, output values corresponding all slot-types\n",
    "        if target_slot is None:\n",
    "            target_slot = list(range(0, self.num_slots))\n",
    "\n",
    "        ds = input_ids.size(0)  # Batch size (B)\n",
    "        ts = input_ids.size(1)  # Max turn size (M)\n",
    "        bs = ds * ts\n",
    "        slot_dim = len(target_slot)  # J\n",
    "\n",
    "        # Utterance encoding\n",
    "        hidden, _ = self.utterance_encoder(\n",
    "            input_ids.view(-1, self.max_seq_length),\n",
    "            token_type_ids.view(-1, self.max_seq_length),\n",
    "            attention_mask.view(-1, self.max_seq_length),\n",
    "        )\n",
    "        hidden = torch.mul(\n",
    "            hidden,\n",
    "            attention_mask.view(-1, self.max_seq_length, 1)\n",
    "            .expand(hidden.size())\n",
    "            .float(),\n",
    "        )\n",
    "        hidden = hidden.repeat(slot_dim, 1, 1)  # [J*M*B, N, H]\n",
    "\n",
    "        hid_slot = self.slot_lookup.weight[\n",
    "            target_slot, :\n",
    "        ]  # Select target slot embedding\n",
    "        hid_slot = hid_slot.repeat(1, bs).view(bs * slot_dim, -1)  # [J*M*B, N, H]\n",
    "\n",
    "        # Attended utterance vector\n",
    "        hidden = self.attn(\n",
    "            hid_slot,  # q^s  [J*M*B, N, H]\n",
    "            hidden,  # U [J*M*B, N, H]\n",
    "            hidden,  # U [J*M*B, N, H]\n",
    "            mask=attention_mask.view(-1, 1, self.max_seq_length).repeat(slot_dim, 1, 1),\n",
    "        )\n",
    "        hidden = hidden.squeeze()  # h [J*M*B, H] Aggregated Slot Context\n",
    "        hidden = hidden.view(slot_dim, ds, ts, -1).view(\n",
    "            -1, ts, self.bert_output_dim\n",
    "        )  # [J*B, M, H]\n",
    "\n",
    "        # NBT\n",
    "        if self.zero_init_rnn:\n",
    "            h = torch.zeros(\n",
    "                self.rnn_num_layers, input_ids.shape[0] * slot_dim, self.hidden_dim\n",
    "            ).to(\n",
    "                self.device\n",
    "            )  # [1, slot_dim*ds, hidden]\n",
    "        else:\n",
    "            h = hidden[:, 0, :].unsqueeze(0).repeat(self.rnn_num_layers, 1, 1)\n",
    "            h = self.rnn_init_linear(h)\n",
    "\n",
    "        if isinstance(self.nbt, nn.GRU):\n",
    "            rnn_out, _ = self.nbt(hidden, h)  # [J*B, M, H_GRU]\n",
    "        elif isinstance(self.nbt, nn.LSTM):\n",
    "            c = torch.zeros(\n",
    "                self.rnn_num_layers, input_ids.shape[0] * slot_dim, self.hidden_dim\n",
    "            ).to(\n",
    "                self.device\n",
    "            )  # [1, slot_dim*ds, hidden]\n",
    "            rnn_out, _ = self.nbt(hidden, (h, c))  # [slot_dim*ds, turn, hidden]\n",
    "        rnn_out = self.layer_norm(self.linear(self.dropout(rnn_out)))\n",
    "\n",
    "        hidden = rnn_out.view(slot_dim, ds, ts, -1)  # [J, B, M, H_GRU]\n",
    "\n",
    "        # Label (slot-value) encoding\n",
    "        loss = 0\n",
    "        loss_slot = []\n",
    "        pred_slot = []\n",
    "        output = []\n",
    "        for s, slot_id in enumerate(target_slot):  ## note: target_slots are successive\n",
    "            # loss calculation\n",
    "            hid_label = self.value_lookup[slot_id].weight\n",
    "            num_slot_labels = hid_label.size(0)\n",
    "\n",
    "            _hid_label = (\n",
    "                hid_label.unsqueeze(0)\n",
    "                .unsqueeze(0)\n",
    "                .repeat(ds, ts, 1, 1)\n",
    "                .view(ds * ts * num_slot_labels, -1)\n",
    "            )\n",
    "            _hidden = (\n",
    "                hidden[s, :, :, :]\n",
    "                .unsqueeze(2)\n",
    "                .repeat(1, 1, num_slot_labels, 1)\n",
    "                .view(ds * ts * num_slot_labels, -1)\n",
    "            )\n",
    "            _dist = self.metric(_hid_label, _hidden).view(ds, ts, num_slot_labels)\n",
    "            _dist = -_dist\n",
    "            _, pred = torch.max(_dist, -1)\n",
    "            pred_slot.append(pred.view(ds, ts, 1))\n",
    "            output.append(_dist)\n",
    "\n",
    "            if labels is not None:\n",
    "                _loss = self.nll(_dist.view(ds * ts, -1), labels[:, :, s].view(-1))\n",
    "                loss_slot.append(_loss.item())\n",
    "                loss += _loss\n",
    "\n",
    "        pred_slot = torch.cat(pred_slot, 2)\n",
    "        if labels is None:\n",
    "            return output, pred_slot\n",
    "\n",
    "        # calculate joint accuracy\n",
    "        accuracy = (pred_slot == labels).view(-1, slot_dim)\n",
    "        acc_slot = (\n",
    "            torch.sum(accuracy, 0).float()\n",
    "            / torch.sum(labels.view(-1, slot_dim) > -1, 0).float()\n",
    "        )\n",
    "        acc = (\n",
    "            sum(torch.sum(accuracy, 1) / slot_dim).float()\n",
    "            / torch.sum(labels[:, :, 0].view(-1) > -1, 0).float()\n",
    "        )  # joint accuracy\n",
    "\n",
    "        if n_gpu == 1:\n",
    "            return loss, loss_slot, acc, acc_slot, pred_slot\n",
    "        else:\n",
    "            return (\n",
    "                loss.unsqueeze(0),\n",
    "                None,\n",
    "                acc.unsqueeze(0),\n",
    "                acc_slot.unsqueeze(0),\n",
    "                pred_slot.unsqueeze(0),\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def init_parameter(module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_normal_(module.weight)\n",
    "            torch.nn.init.constant_(module.bias, 0.0)\n",
    "        elif isinstance(module, nn.GRU) or isinstance(module, nn.LSTM):\n",
    "            torch.nn.init.xavier_normal_(module.weight_ih_l0)\n",
    "            torch.nn.init.xavier_normal_(module.weight_hh_l0)\n",
    "            torch.nn.init.constant_(module.bias_ih_l0, 0.0)\n",
    "            torch.nn.init.constant_(module.bias_hh_l0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYm56GEZ6B7u"
   },
   "source": [
    "## TODO-2: Ontology Pre-Encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WdPyqp16B7w"
   },
   "source": [
    "Ontology의 slot type들과 이에 속하는 slot_value들을 tokenizing하는 `tokenize_ontology`를 작성하세요. <br>\n",
    "[CLS] Pooling하여 `slot_lookup` 과 `value_lookup` embedding matrix들을 초기화하는 <br>\n",
    "`initialize_slot_value_lookup`에 인자로 넘겨주세요. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zwgNUZNn6B7w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_ontology(ontology, tokenizer, max_seq_length=12):\n",
    "    # TODO\n",
    "#     raise Exception('ontology 의 slot, value를 tokenizing하는 코드를 작성하세요!')\n",
    "    # Your code here!\n",
    "    slot_types=[]\n",
    "    slot_values=[]\n",
    "    for slot, values in ontology.items():\n",
    "        slot=tokenizer.encode(slot)\n",
    "        if len(slot) < max_seq_length:\n",
    "            gap = max_seq_length - len(slot)\n",
    "            slot.extend([tokenizer.pad_token_id] * gap)\n",
    "        slot_types.append(slot)\n",
    "        val_list=[]\n",
    "        for value in values:\n",
    "            value=tokenizer.encode(value)\n",
    "            if len(value) < max_seq_length:\n",
    "                gap = max_seq_length - len(value)\n",
    "                value.extend([tokenizer.pad_token_id] * gap)\n",
    "            val_list.append(value)\n",
    "        slot_values.append(torch.LongTensor(val_list))\n",
    "    # Your code here!\n",
    "    return torch.LongTensor(slot_types), slot_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "attmAW3A6B7w",
    "outputId": "9dbf4e3d-f077-4782-9d3b-d7c8c00159ff",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Slot:  torch.Size([45, 12])\n",
      "Tokenized Value of 관광-경치 좋은 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-교육적 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-도보 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-문화 예술 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-역사적 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-이름 torch.Size([103, 12])\n",
      "Tokenized Value of 관광-종류 torch.Size([13, 12])\n",
      "Tokenized Value of 관광-주차 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-지역 torch.Size([7, 12])\n",
      "Tokenized Value of 숙소-가격대 torch.Size([5, 12])\n",
      "Tokenized Value of 숙소-도보 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-수영장 유무 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-스파 유무 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-예약 기간 torch.Size([12, 12])\n",
      "Tokenized Value of 숙소-예약 명수 torch.Size([12, 12])\n",
      "Tokenized Value of 숙소-예약 요일 torch.Size([9, 12])\n",
      "Tokenized Value of 숙소-이름 torch.Size([67, 12])\n",
      "Tokenized Value of 숙소-인터넷 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-조식 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-종류 torch.Size([7, 12])\n",
      "Tokenized Value of 숙소-주차 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-지역 torch.Size([7, 12])\n",
      "Tokenized Value of 숙소-헬스장 유무 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-흡연 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-가격대 torch.Size([5, 12])\n",
      "Tokenized Value of 식당-도보 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-야외석 유무 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-예약 명수 torch.Size([12, 12])\n",
      "Tokenized Value of 식당-예약 시간 torch.Size([569, 12])\n",
      "Tokenized Value of 식당-예약 요일 torch.Size([9, 12])\n",
      "Tokenized Value of 식당-이름 torch.Size([44, 12])\n",
      "Tokenized Value of 식당-인터넷 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-종류 torch.Size([10, 12])\n",
      "Tokenized Value of 식당-주류 판매 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-주차 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-지역 torch.Size([7, 12])\n",
      "Tokenized Value of 식당-흡연 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 지하철-도착지 torch.Size([60, 12])\n",
      "Tokenized Value of 지하철-출발 시간 torch.Size([12, 12])\n",
      "Tokenized Value of 지하철-출발지 torch.Size([60, 12])\n",
      "Tokenized Value of 택시-도착 시간 torch.Size([190, 12])\n",
      "Tokenized Value of 택시-도착지 torch.Size([298, 12])\n",
      "Tokenized Value of 택시-종류 torch.Size([5, 12])\n",
      "Tokenized Value of 택시-출발 시간 torch.Size([431, 12])\n",
      "Tokenized Value of 택시-출발지 torch.Size([286, 12])\n"
     ]
    }
   ],
   "source": [
    "slot_type_ids, slot_values_ids = tokenize_ontology(ontology, tokenizer, 12)\n",
    "num_labels = [len(s) for s in slot_values_ids]  # 각 Slot 별 후보 Values의 갯수\n",
    "\n",
    "print(\"Tokenized Slot: \", slot_type_ids.size())\n",
    "for slot, slot_value_id in zip(slot_meta, slot_values_ids):\n",
    "    print(f\"Tokenized Value of {slot}\", slot_value_id.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCsCGN0f6B7x"
   },
   "source": [
    "## Model 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aQSRYG6e6B7x",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = {\n",
    "    'hidden_dim': 300,\n",
    "    'num_rnn_layers': 1,\n",
    "    'zero_init_rnn': False,\n",
    "    'max_seq_length': 128,\n",
    "    'max_label_length': 12,\n",
    "    'attn_head': 4,\n",
    "    'fix_utterance_encoder': False,\n",
    "    'task_name': 'sumbtgru',\n",
    "    'distance_metric': 'euclidean',\n",
    "    'model_name_or_path': 'dsksd/bert-ko-small-minimal',\n",
    "    'warmup_ratio': 0.1,\n",
    "    'learning_rate': 5e-5,\n",
    "    'weight_decay': 0.01,\n",
    "    'num_train_epochs': 10 #원래 10\n",
    "}\n",
    "\n",
    "args = Namespace(**args)\n",
    "\n",
    "num_labels = [len(s) for s in slot_values_ids]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_gpu = 1 if torch.cuda.device_count() < 2 else torch.cuda.device_count()\n",
    "n_epochs = args.num_train_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NZNUF9k86B7x",
    "outputId": "4ef347fd-6fa1-4f26-e8a4-8133614f9380",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dsksd/bert-ko-small-minimal were not used when initializing BertForUtteranceEncoding: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at dsksd/bert-ko-small-minimal were not used when initializing BertForUtteranceEncoding: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete initialization of slot and value lookup\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SUMBT(args, num_labels, device)\n",
    "model.initialize_slot_value_lookup(slot_values_ids, slot_type_ids)  # Tokenized Ontology의 Pre-encoding using BERT_SV\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulJJGp5a6B7x"
   },
   "source": [
    "## 데이터 로더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yBU7KP5A6B7y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data_utils import WOSDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import random\n",
    "\n",
    "\n",
    "train_data = WOSDataset(train_features)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(train_data, batch_size=4, sampler=train_sampler, collate_fn=processor.collate_fn)\n",
    "\n",
    "dev_data = WOSDataset(dev_features)\n",
    "dev_sampler = SequentialSampler(dev_data)\n",
    "dev_loader = DataLoader(dev_data, batch_size=4, sampler=dev_sampler, collate_fn=processor.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVQC_XUG6B7y"
   },
   "source": [
    "## Optimizer & Scheduler 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wK-LWnHU6B7y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "t_total = len(train_loader) * n_epochs\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=int(t_total * args.warmup_ratio), num_training_steps=t_total\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-f0L44h6B7y"
   },
   "source": [
    "## TODO-3: Inference code 작성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jCGuenx36B7y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from evaluation import _evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LBXWTFHi6B7y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model, eval_loader, processor, device):\n",
    "    model.eval()\n",
    "    predictions = {}\n",
    "    for batch in tqdm(eval_loader):\n",
    "        input_ids, segment_ids, input_masks, target_ids, num_turns, guids  = \\\n",
    "        [b.to(device) if not isinstance(b, list) else b for b in batch]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, pred_slot = model(input_ids, segment_ids, input_masks, None, 9)\n",
    "            \n",
    "#         for guid, preds, n_turn in zip(guids, pred_slot.tolist(), num_turns):\n",
    "#             prediction = processor.recover_state(preds, n_turn)\n",
    "\n",
    "#             for i in range(n_turn):\n",
    "#                 turn_guid = guid + '-' + str(i)\n",
    "#                 predictions[turn_guid] = prediction[i]\n",
    "#     return predictions\n",
    "        batch_size = input_ids.size(0)\n",
    "        for i in range(batch_size):\n",
    "            guid = guids[i]\n",
    "            states = processor.recover_state(pred_slot.tolist()[i], num_turns[i])\n",
    "            for tid, state in enumerate(states):\n",
    "                predictions[f\"{guid}-{tid}\"] = state\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_list=[] #에폭별로 wrong_answer를 담아둘 배열\n",
    "correct_list=[] #wrong_list의 에폭별 오답률을 위해 correct_answer를 담아둘 배열"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mW-qyUd_6B7y"
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "S7tpx4426B7z",
    "outputId": "9538d5cc-c271-4176-e1a1-af2d1121c40c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71356dc3c67a47efb9a1e95a196aa015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10] [0/788] 111.170555\n",
      "[0/10] [100/788] 44.437187\n",
      "[0/10] [200/788] 43.629490\n",
      "[0/10] [300/788] 32.353809\n",
      "[0/10] [400/788] 31.247683\n",
      "[0/10] [500/788] 22.681833\n",
      "[0/10] [600/788] 22.234411\n",
      "[0/10] [700/788] 24.661880\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40ebadb7a314e248ac2c36c3f3ab61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'joint_goal_accuracy': 0.036546819438956935, 'turn_slot_accuracy': 0.8636551209447303, 'turn_slot_f1': 0.34077969783643214}\n",
      "[('숙소', 15707), ('식당', 15511), ('관광', 5967), ('택시', 3360), ('지하철', 292)]\n",
      "[('종류', 6786), ('지역', 6106), ('이름', 5479), ('가격대', 4344), ('예약 요일', 3831)]\n",
      "[('dontcare', 5602), ('yes', 3471), ('1', 1248), ('서울 중앙', 1237), ('서울 북쪽', 1125)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_goal_accuracy: 0.036546819438956935\n",
      "turn_slot_accuracy: 0.8636551209447303\n",
      "turn_slot_f1: 0.34077969783643214\n",
      "Update Best checkpoint!\n",
      "Best checkpoint: /opt/ml/model_ckpt/model-0.bin\n",
      "score is : 0.036546819438956935\n",
      "[1/10] [0/788] 17.472647\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-714cafea7774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_gpu\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_slot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_slot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_slot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-e1d5cff70e72>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, labels, n_gpu, target_slot)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0m_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mloss_slot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from eda import getWrong_Domain_Slot_Value_distribution_counter,getOriginal_Slot_Value_distribution_counter,draw_EDA\n",
    "from collections import Counter\n",
    "\n",
    "best_score, best_checkpoint = 0, 0\n",
    "model_location=\"/opt/ml/model_ckpt\"\n",
    "best_model=\"\"\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    batch_loss = []\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        input_ids, segment_ids, input_masks, target_ids, num_turns, guids  = \\\n",
    "        [b.to(device) if not isinstance(b, list) else b for b in batch]\n",
    "\n",
    "        # Forward\n",
    "        if n_gpu == 1:\n",
    "            loss, loss_slot, acc, acc_slot, _ = model(input_ids, segment_ids, input_masks, target_ids, n_gpu)\n",
    "        else:\n",
    "            loss, _, acc, acc_slot, _ = model(input_ids, segment_ids, input_masks, target_ids, n_gpu)\n",
    "        \n",
    "        batch_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        if step % 100 == 0:\n",
    "            print('[%d/%d] [%d/%d] %f' % (epoch, n_epochs, step, len(train_loader), loss.item()))\n",
    "    \n",
    "    #현재 에폭에서의 wrong_list 저장\n",
    "    predictions = inference(model, dev_loader, processor, device)\n",
    "    \n",
    "    # 현재 에폭에서 eval_result 외에도 틀린 예측값, ground truth값을 뽑아낸다\n",
    "    eval_result,now_wrong_list,now_correct_list = _evaluation(predictions, dev_labels, slot_meta)\n",
    "    #eda\n",
    "    \n",
    "    domain_counter,_,_=getWrong_Domain_Slot_Value_distribution_counter(Counter(now_wrong_list))\n",
    "    o_domain_counter,_,_=getOriginal_Slot_Value_distribution_counter(Counter(now_correct_list))\n",
    "    draw_EDA(domain_counter,o_domain_counter)\n",
    "    \n",
    "    wrong_list.append(now_wrong_list)\n",
    "    correct_list.append(now_correct_list)\n",
    "    for k, v in eval_result.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "        \n",
    "    if best_score < eval_result['joint_goal_accuracy']:\n",
    "            print(\"Update Best checkpoint!\")\n",
    "            best_score = eval_result['joint_goal_accuracy']\n",
    "            best_checkpoint = epoch\n",
    "\n",
    "            torch.save(model.state_dict(), f\"{model_location}/model-{epoch}.bin\")\n",
    "            best_model=f\"{model_location}/model-{epoch}.bin\"\n",
    "    print(f\"Best checkpoint: {model_location}/model-{best_checkpoint}.bin\")\n",
    "    print(f\"score is : {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실험코드\n",
    "from eval_utils import DSTEvaluator\n",
    "def _evaluation(preds, labels, slot_meta):\n",
    "    evaluator = DSTEvaluator(slot_meta)\n",
    "\n",
    "    evaluator.init()\n",
    "    assert len(preds) == len(labels)\n",
    "    \n",
    "    wrong_list=[]\n",
    "    correct_list=[]\n",
    "    for k, l in labels.items():\n",
    "        p = preds.get(k)\n",
    "        if p is None:\n",
    "            raise Exception(f\"{k} is not in the predictions!\")\n",
    "        evaluator.update(l, p)\n",
    "        wrong_list.extend(set(l)-set(p))\n",
    "        correct_list.extend(set(l))\n",
    "    result = evaluator.compute()\n",
    "    print(result)\n",
    "    return result,wrong_list,correct_list\n",
    "a,b,c=_evaluation(predictions,dev_labels,slot_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #prediction의 오답 트랜드 출력\n",
    "# from eda import getWrong_Domain_Slot_Value_distribution_counter,getOriginal_Slot_Value_distribution_counter,draw_EDA\n",
    "\n",
    "# getWrong_Domain_Slot_Value_distribution_counter(Counter(wrong_list[0]))\n",
    "# draw_EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHUyY11B6B70"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VzusVESG6B70",
    "outputId": "972f9d9f-336e-452d-c535-0aef4638f40f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_data = json.load(open(f\"/opt/ml/input/data/eval_dataset/eval_dials.json\", \"r\"))\n",
    "\n",
    "eval_examples = get_examples_from_dialogues(\n",
    "    eval_data, user_first=True, dialogue_level=True\n",
    ")\n",
    "\n",
    "# Extracting Featrues\n",
    "eval_features = processor.convert_examples_to_features(eval_examples)\n",
    "eval_data = WOSDataset(eval_features)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_loader = DataLoader(\n",
    "    eval_data,\n",
    "    batch_size=5,\n",
    "    sampler=eval_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88F6j_5v6B71",
    "outputId": "9fdd691f-2974-47d4-f71c-fd454048f9eb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = inference(model, eval_loader, processor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-IQhzx16B71"
   },
   "outputs": [],
   "source": [
    "json.dump(predictions, open('predictions2.csv', 'w'), indent=2, ensure_ascii=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions['square-silence-9151:숙소_관광_11-0']\n",
    "# for k in dev_labels.keys():\n",
    "#     if 'square-silence-9151:숙소_관광_11-0' in k:\n",
    "#         print(k)\n",
    "#         break\n",
    "# else :\n",
    "#     print(1)\n",
    "# # 'square-silence-9151:숙소_관광_11-0' in dev_labels.keys()\n",
    "# a='square_111'\n",
    "# b='asdas_square_111'\n",
    "# print(b.find(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ###EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda import getWrong_Domain_Slot_Value_distribution_counter,getOriginal_Slot_Value_distribution_counter,draw_EDA\n",
    "domain_counter,_,_=getWrong_Domain_Slot_Value_distribution_counter(Counter(wrong))\n",
    "o_domain_counter,_,_getOriginal_Slot_Value_distribution_counter(Counter(dev_labels))\n",
    "draw_EDA(domain_counter,o_domain_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_list=[]\n",
    "for k,v in predictions.items():\n",
    "    if \"지하철\" in k:\n",
    "        subway_list.append(k.split(':')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subway_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p,l in zip(predictions.items(),dev_labels.items()):\n",
    "    if subway_list[0] in p[0] and p[0]==l[0]:\n",
    "        print(1)\n",
    "        if set(p[1])!=set(l[1]) :\n",
    "            print(\"id\",p[0])\n",
    "            print(\"pred: \",list(filter(lambda x : '지하철' in x, p[1])))\n",
    "            print(\"answr: \",list(filter(lambda x : '지하철' in x, l[1])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dev_labels.items():\n",
    "    if subway_list[0] in k:\n",
    "        print(\"id:\",k)\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for epoch, wrong in enumerate(wrong_list):\n",
    "        if epoch%3==0:\n",
    "            plt.title('wrong num per domain')\n",
    "        domain_counter,slot_counter,value_counter=getWrong_Domain_Slot_Value_distribution_counter(Counter(wrong))\n",
    "        plt.plot(['tour', 'restourant', 'taxi', 'hotel', 'subway'],domain_counter.values(), label=f\"ep{epoch} domain\")\n",
    "        if epoch%3==0 and epoch!=0:\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SUMBT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
