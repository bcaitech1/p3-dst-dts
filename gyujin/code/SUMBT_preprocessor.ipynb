{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e747e7-f5c2-44fe-80b8-54f919fa9720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer, AutoTokenizer\n",
    "from data_utils import get_examples_from_dialogues, convert_state_dict, load_dataset\n",
    "from data_utils import OntologyDSTFeature, DSTPreprocessor, _truncate_seq_pair\n",
    "\n",
    "from torch.cuda.amp import autocast,  GradScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a098517-9ff1-4774-9c32-a143f14d68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__\n",
    "use_amp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f311cb03-6bb6-42cb-b2db-a395e3188ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"/opt/ml/input/data/train_dataset/train_dials.json\"\n",
    "slot_meta = json.load(open(\"/opt/ml/input/data/train_dataset/slot_meta.json\"))\n",
    "ontology = json.load(open(\"/opt/ml/input/data/train_dataset/ontology.json\"))\n",
    "train_data, dev_data, dev_labels = load_dataset(train_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77167e68-4092-4bfc-97f9-7d3e2fda3384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = {\n",
    "    'hidden_dim': 300,\n",
    "    'num_rnn_layers': 1,\n",
    "    'zero_init_rnn': False,\n",
    "    'max_seq_length': 64,\n",
    "    'max_label_length': 12,\n",
    "    'attn_head': 4,\n",
    "    'fix_utterance_encoder': False,\n",
    "    'task_name': 'sumbtgru',\n",
    "    'distance_metric': 'euclidean',\n",
    "    'model_name_or_path': 'monologg/koelectra-base-v3-discriminator',\n",
    "    'warmup_ratio': 0.1,\n",
    "    'learning_rate': 5e-5,\n",
    "    'weight_decay': 0.01,\n",
    "    'num_train_epochs': 10,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "args = Namespace(**args)\n",
    "args.model_name_or_path = 'dsksd/bert-ko-small-minimal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4e1c1a1-5743-4813-b7c5-b9838ec11865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26487241de5417f92309830ad0af278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6301.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863f624ea6c74c3f99167888ad5fbfd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=699.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_examples = get_examples_from_dialogues(data=train_data,\n",
    "                                             user_first=True,\n",
    "                                             dialogue_level=True)\n",
    "\n",
    "dev_examples = get_examples_from_dialogues(data=dev_data,\n",
    "                                           user_first=True,\n",
    "                                           dialogue_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f32c756-9847-4d4e-abd2-c1ba6e2801c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DSTInputExample(guid='snowy-hat-8324:관광_식당_11-5', context_turns=['', '서울 중앙에 있는 박물관을 찾아주세요', '안녕하세요. 문화역서울 284은 어떠신가요? 평점도 4점으로 방문객들에게 좋은 평가를 받고 있습니다.', '좋네요 거기 평점은 말해주셨구 전화번호가 어떻게되나요?', '전화번호는 983880764입니다. 더 필요하신 게 있으실까요?', '네 관광지와 같은 지역의 한식당을 가고싶은데요 야외석이 있어야되요', '생각하고 계신 가격대가 있으신가요?', '음.. 저렴한 가격대에 있나요?', '죄송하지만 저렴한 가격대에는 없으시네요.', '그럼 비싼 가격대로 다시 찾아주세요'], current_turn=['좋습니당 토요일 18:00에 1명 예약가능한가요?', '외계인의맛집은 어떠신가요? 대표 메뉴는 한정식입니다.'], label=['관광-종류-박물관', '관광-지역-서울 중앙', '관광-이름-문화역서울 284', '식당-가격대-비싼', '식당-지역-서울 중앙', '식당-종류-한식당', '식당-야외석 유무-yes', '식당-예약 요일-토요일', '식당-예약 시간-18:00', '식당-예약 명수-1', '식당-이름-외계인의맛집'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63c54cf8-befa-44a1-a45c-92160c0c79bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]['dialogue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94097e7d-9d74-49f5-bc64-da8369981b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_turn = max([len(e['dialogue']) for e in train_data])\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4a2e0ac-c3f3-4649-8678-b55d4926e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from data_utils import get_examples_from_dialogues, convert_state_dict, load_dataset\n",
    "from data_utils import OntologyDSTFeature, DSTPreprocessor, _truncate_seq_pair\n",
    "\n",
    "class SUMBTPreprocessor(DSTPreprocessor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        slot_meta,\n",
    "        src_tokenizer,\n",
    "        trg_tokenizer=None,\n",
    "        ontology=None,\n",
    "        max_seq_length=64,\n",
    "        max_turn_length=14,\n",
    "    ):\n",
    "        self.slot_meta = slot_meta\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.trg_tokenizer = trg_tokenizer if trg_tokenizer else src_tokenizer\n",
    "        self.ontology = ontology\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.max_turn_length = max_turn_length\n",
    "\n",
    "    def _convert_example_to_feature(self, example):\n",
    "        guid = example[0].guid.rsplit(\"-\", 1)[0]  # dialogue_idx\n",
    "        turns = []\n",
    "        token_types = []\n",
    "        labels = []\n",
    "        num_turn = None\n",
    "        for turn in example[: self.max_turn_length]:\n",
    "            assert len(turn.current_turn) == 2\n",
    "            uttrs = []\n",
    "            for segment_idx, uttr in enumerate(turn.current_turn):\n",
    "                token = self.src_tokenizer.encode(uttr, add_special_tokens=False)\n",
    "                uttrs.append(token)\n",
    "\n",
    "            _truncate_seq_pair(uttrs[0], uttrs[1], self.max_seq_length - 3)\n",
    "            tokens = (\n",
    "                [self.src_tokenizer.cls_token_id]\n",
    "                + uttrs[0]\n",
    "                + [self.src_tokenizer.sep_token_id]\n",
    "                + uttrs[1]\n",
    "                + [self.src_tokenizer.sep_token_id]\n",
    "            )\n",
    "            token_type = [0] * (len(uttrs[0]) + 2) + [1] * (len(uttrs[1]) + 1)\n",
    "            if len(tokens) < self.max_seq_length:\n",
    "                gap = self.max_seq_length - len(tokens)\n",
    "                tokens.extend([self.src_tokenizer.pad_token_id] * gap)\n",
    "                token_type.extend([0] * gap)\n",
    "            turns.append(tokens)\n",
    "            token_types.append(token_type)\n",
    "            label = []\n",
    "            if turn.label:\n",
    "                slot_dict = convert_state_dict(turn.label)\n",
    "            else:\n",
    "                slot_dict = {}\n",
    "            for slot_type in self.slot_meta:\n",
    "                value = slot_dict.get(slot_type, \"none\")\n",
    "                \n",
    "                if value in ontology[slot_type]:\n",
    "                    label_idx = ontology[slot_type].index(value)\n",
    "                else:\n",
    "                    label_idx = ontology[slot_type].index('none')\n",
    "               \n",
    "                label.append(label_idx)\n",
    "            labels.append(label)\n",
    "        num_turn = len(turns)\n",
    "        if len(turns) < self.max_turn_length:\n",
    "            gap = self.max_turn_length - len(turns)\n",
    "            for _ in range(gap):\n",
    "                dummy_turn = [self.src_tokenizer.pad_token_id] * self.max_seq_length\n",
    "                turns.append(dummy_turn)\n",
    "                token_types.append(dummy_turn)\n",
    "                dummy_label = [-1] * len(self.slot_meta)\n",
    "                labels.append(dummy_label)\n",
    "        return OntologyDSTFeature(\n",
    "            guid=guid,\n",
    "            input_ids=turns,\n",
    "            segment_ids=token_types,\n",
    "            num_turn=num_turn,\n",
    "            target_ids=labels,\n",
    "        )\n",
    "\n",
    "    def convert_examples_to_features(self, examples):\n",
    "        return list(map(self._convert_example_to_feature, tqdm(examples)))\n",
    "\n",
    "    def recover_state(self, pred_slots, num_turn):\n",
    "        states = []\n",
    "        \n",
    "        for pred_slot in pred_slots[:num_turn]:\n",
    "            state = []\n",
    "            for s, p in zip(self.slot_meta, pred_slot):\n",
    "                v = self.ontology[s][p]\n",
    "                if v != 'none':\n",
    "                    state.append(f'{s}-{v}')\n",
    "                    \n",
    "            states.append(state)\n",
    "            \n",
    "        return states\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        guids = [b.guid for b in batch]\n",
    "        input_ids = torch.LongTensor([b.input_ids for b in batch])\n",
    "        segment_ids = torch.LongTensor([b.segment_ids for b in batch])\n",
    "        input_masks = input_ids.ne(self.src_tokenizer.pad_token_id)\n",
    "        target_ids = torch.LongTensor([b.target_ids for b in batch])\n",
    "        num_turns = [b.num_turn for b in batch]\n",
    "        return input_ids, segment_ids, input_masks, target_ids, num_turns, guids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8714ed3a-f963-4618-aae7-b8feb8b9fe25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6301"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0d7353e-0b29-4d53-8613-1981b5e81ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc101a5f96542b59805ab6218e9249d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6301.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718a5ddc552f49bdb6e17bf74a4c911a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=699.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "processor = SUMBTPreprocessor(slot_meta,\n",
    "                              tokenizer,\n",
    "                              ontology=ontology,  # predefined ontology\n",
    "                              max_seq_length=64,  # 각 turn마다 최대 길이\n",
    "                              max_turn_length=max_turn)  # 각 dialogue의 최대 turn 길이\n",
    "train_features = processor.convert_examples_to_features(train_examples)\n",
    "dev_features = processor.convert_examples_to_features(dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "355ab239-b480-40d3-843f-cd792a949921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6301\n",
      "699\n"
     ]
    }
   ],
   "source": [
    "print(len(train_features))  # 대화 level의 features\n",
    "print(len(dev_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cc2e6b5-a2a0-4a63-a50b-957cd405000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids, segment_ids, input_masks, target_ids, num_turns, guids \n",
    "# print()\n",
    "# model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df971390-7e77-4b5e-bb27-0d1028a4d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = AutoForUtteranceEncoding.from_pretrained(args.model_name_or_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dedb8925-6ef2-4aa4-b045-95dbf5e53a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b.hidden_states[-1].shape, input_ids.view(-1, 64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0b63f0e-6269-4929-b602-0f131af9f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = a.base(input_ids.view(-1, 64), segment_ids.view(-1, 64), input_masks.long().view(-1, 64),\n",
    "# #             output_attentions=False,\n",
    "#             output_hidden_states=True,\n",
    "#             return_dict=True,\n",
    "#         )\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75308393-cd47-4185-8558-ae0e69ea191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "432b4353-386f-454b-a45d-b3708ea002fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.base(input_ids=input_ids.view(-1, 64), token_type_ids=segment_ids.view(-1, 64), attention_mask=input_masks.view(-1, 64))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8555944-76da-4081-83de-a54b6d059a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = AutoForUtteranceEncoding.from_pretrained('dsksd/bert-ko-small-minimal').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5588b5b-72a8-4800-8b7a-83616819f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = c.base(input_ids.view(-1, 64), segment_ids.view(-1, 64), input_masks.long().view(-1, 64),\n",
    "# #             output_attentions=False,\n",
    "#             output_hidden_states=True,\n",
    "#             return_dict=True,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba937707-914b-457f-af2e-b1b0d7685a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2b7f0e0-77c5-4156-97fb-7f0750037a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Most of code is from https://github.com/SKTBrain/SUMBT\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CosineEmbeddingLoss, CrossEntropyLoss\n",
    "from transformers import BertModel, BertPreTrainedModel, AutoModel, AutoModelForPreTraining, AutoConfig\n",
    "\n",
    "class AutoForUtteranceEncoding(nn.Module):\n",
    "    def __init__(self, config, model):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.base = model\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
    "        return self.base(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs):\n",
    "        config = AutoConfig.from_pretrained(pretrained_model_name_or_path, **kwargs)\n",
    "        model = AutoModelForPreTraining.from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n",
    "        ret = cls(config, model)\n",
    "        return ret\n",
    "\n",
    "class BertForUtteranceEncoding(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertForUtteranceEncoding, self).__init__(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.base = BertModel(config)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
    "        return self.base(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.scores = None\n",
    "\n",
    "    def attention(self, q, k, v, d_k, mask=None, dropout=None):\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "            mask = mask.to(dtype=scores.dtype)\n",
    "            mask = (1.0 - mask) * -10000.0\n",
    "            scores = scores + mask\n",
    "            \n",
    "        scores = F.softmax(scores, dim=-1)\n",
    "\n",
    "        if dropout is not None:\n",
    "            scores = dropout(scores)\n",
    "\n",
    "        self.scores = scores\n",
    "        output = torch.matmul(scores, v)\n",
    "        return output\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        bs = q.size(0)\n",
    "\n",
    "        # perform linear operation and split into h heads\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "\n",
    "        # transpose to get dimensions bs * h * sl * d_model\n",
    "        k = k.transpose(1, 2)\n",
    "        q = q.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        scores = self.attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "\n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n",
    "        output = self.out(concat)\n",
    "        return output\n",
    "\n",
    "    def get_scores(self):\n",
    "        return self.scores\n",
    "\n",
    "\n",
    "class SUMBT(nn.Module):\n",
    "    def __init__(self, args, num_labels, device):\n",
    "        super(SUMBT, self).__init__()\n",
    "\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.rnn_num_layers = args.num_rnn_layers\n",
    "        self.zero_init_rnn = args.zero_init_rnn\n",
    "        self.max_seq_length = args.max_seq_length\n",
    "        self.max_label_length = args.max_label_length\n",
    "        self.num_labels = num_labels\n",
    "        self.num_slots = len(num_labels)\n",
    "        self.attn_head = args.attn_head\n",
    "        self.device = device\n",
    "\n",
    "        ### Utterance Encoder\n",
    "        self.utterance_encoder = AutoForUtteranceEncoding.from_pretrained(\n",
    "            args.model_name_or_path\n",
    "        )\n",
    "        self.bert_output_dim = self.utterance_encoder.config.hidden_size\n",
    "        self.hidden_dropout_prob = self.utterance_encoder.config.hidden_dropout_prob\n",
    "        if args.fix_utterance_encoder:\n",
    "            for p in self.utterance_encoder.base.pooler.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        ### slot, slot-value Encoder (not trainable)\n",
    "        self.sv_encoder = AutoForUtteranceEncoding.from_pretrained(\n",
    "            args.model_name_or_path\n",
    "        )\n",
    "        # os.path.join(args.bert_dir, 'bert-base-uncased.model'))\n",
    "        for p in self.sv_encoder.base.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.slot_lookup = nn.Embedding(self.num_slots, self.bert_output_dim)\n",
    "        self.value_lookup = nn.ModuleList(\n",
    "            [nn.Embedding(num_label, self.bert_output_dim) for num_label in num_labels]\n",
    "        )\n",
    "\n",
    "        ### Attention layer\n",
    "        self.attn = MultiHeadAttention(self.attn_head, self.bert_output_dim, dropout=0)\n",
    "\n",
    "        ### RNN Belief Tracker\n",
    "        self.nbt = nn.GRU(\n",
    "            input_size=self.bert_output_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.rnn_num_layers,\n",
    "            dropout=self.hidden_dropout_prob,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.init_parameter(self.nbt)\n",
    "\n",
    "        if not self.zero_init_rnn:\n",
    "            self.rnn_init_linear = nn.Sequential(\n",
    "                nn.Linear(self.bert_output_dim, self.hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.hidden_dropout_prob),\n",
    "            )\n",
    "\n",
    "        self.linear = nn.Linear(self.hidden_dim, self.bert_output_dim)\n",
    "        self.layer_norm = nn.LayerNorm(self.bert_output_dim)\n",
    "\n",
    "        ### Measure\n",
    "        self.metric = torch.nn.PairwiseDistance(p=2.0, eps=1e-06, keepdim=False)\n",
    "\n",
    "        ### Classifier\n",
    "        self.nll = CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "        ### Etc.\n",
    "        self.dropout = nn.Dropout(self.hidden_dropout_prob)\n",
    "\n",
    "    def initialize_slot_value_lookup(self, label_ids, slot_ids):\n",
    "\n",
    "        self.sv_encoder.eval()\n",
    "\n",
    "        # Slot encoding\n",
    "        slot_type_ids = torch.zeros(slot_ids.size(), dtype=torch.long).to(\n",
    "            slot_ids.device\n",
    "        )\n",
    "        slot_mask = slot_ids > 0\n",
    "        hid_slot = self.sv_encoder(\n",
    "            slot_ids.view(-1, self.max_label_length),\n",
    "            slot_type_ids.view(-1, self.max_label_length),\n",
    "            slot_mask.view(-1, self.max_label_length),\n",
    "        ).hidden_states[-1]\n",
    "        \n",
    "        hid_slot = hid_slot[:, 0, :]\n",
    "        hid_slot = hid_slot.detach()\n",
    "    \n",
    "        self.slot_lookup = nn.Embedding.from_pretrained(hid_slot, freeze=True)\n",
    "        assert self.slot_lookup.weight.shape == (self.num_slots, self.bert_output_dim)\n",
    "\n",
    "        for s, label_id in enumerate(label_ids):\n",
    "            label_type_ids = torch.zeros(label_id.size(), dtype=torch.long).to(\n",
    "                label_id.device\n",
    "            )\n",
    "            label_mask = label_id > 0\n",
    "            hid_label = self.sv_encoder(\n",
    "                label_id.view(-1, self.max_label_length),\n",
    "                label_type_ids.view(-1, self.max_label_length),\n",
    "                label_mask.view(-1, self.max_label_length),\n",
    "            ).hidden_states[-1]\n",
    "            hid_label = hid_label[:, 0, :]\n",
    "            hid_label = hid_label.detach()\n",
    "            self.value_lookup[s] = nn.Embedding.from_pretrained(hid_label, freeze=True)\n",
    "            self.value_lookup[s].padding_idx = -1\n",
    "            assert self.value_lookup[s].weight.shape == (label_id.size(0), self.bert_output_dim)\n",
    "\n",
    "        print(\"Complete initialization of slot and value lookup\")\n",
    "        self.sv_encoder = None\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        token_type_ids,\n",
    "        attention_mask,\n",
    "        labels=None,\n",
    "        n_gpu=1,\n",
    "        target_slot=None,\n",
    "    ):\n",
    "        # B = Batch Size\n",
    "        # M = Max Turn Size\n",
    "        # N = Seq Len\n",
    "        # J = Target_slot Len\n",
    "        # H_GRU = RNN Hidden Dim\n",
    "        \n",
    "        # input_ids: [B, M, N]\n",
    "        # token_type_ids: [B, M, N]\n",
    "        # attention_mask: [B, M, N]\n",
    "        # labels: [B, M, J]\n",
    "\n",
    "        # if target_slot is not specified, output values corresponding all slot-types\n",
    "        if target_slot is None:\n",
    "            target_slot = list(range(0, self.num_slots))\n",
    "\n",
    "        ds = input_ids.size(0)  # Batch size (B)\n",
    "        ts = input_ids.size(1)  # Max turn size (M)\n",
    "        bs = ds * ts # B * M\n",
    "        slot_dim = len(target_slot)  # J\n",
    "\n",
    "        # Utterance encoding\n",
    "        hidden = self.utterance_encoder(\n",
    "            input_ids.view(-1, self.max_seq_length),\n",
    "            token_type_ids.view(-1, self.max_seq_length),\n",
    "            attention_mask.view(-1, self.max_seq_length),\n",
    "        ).hidden_states[-1] # [B*M, N, H]\n",
    "\n",
    "        hidden = torch.mul(\n",
    "            hidden,\n",
    "            attention_mask.view(-1, self.max_seq_length, 1)\n",
    "            .expand(hidden.size())\n",
    "            .float(),\n",
    "        )\n",
    "        hidden = hidden.repeat(slot_dim, 1, 1)  # [J*M*B, N, H]\n",
    "\n",
    "        hid_slot = self.slot_lookup.weight[\n",
    "            target_slot, :\n",
    "        ]  # Select target slot embedding # [J, H]\n",
    "        hid_slot = hid_slot.repeat(1, bs).view(bs * slot_dim, -1)  # [J*M*B, H]\n",
    "\n",
    "        # Attended utterance vector\n",
    "        hidden = self.attn(\n",
    "            hid_slot,  # q^s  [J*M*B, H] => [J*M*B, 1, H]\n",
    "            hidden,  # U [J*M*B, N, H]\n",
    "            hidden,  # U [J*M*B, N, H]\n",
    "            mask=attention_mask.view(-1, 1, self.max_seq_length).repeat(slot_dim, 1, 1),\n",
    "        ) # [J*M*B, 1, H] -> 1 = hid_slot_seq_len\n",
    "        hidden = hidden.squeeze()  # h [J*M*B, H] Aggregated Slot Context\n",
    "        hidden = hidden.view(slot_dim, ds, ts, -1).view(\n",
    "            -1, ts, self.bert_output_dim\n",
    "        )  # [J*B, M, H]\n",
    "\n",
    "        # NBT\n",
    "        if self.zero_init_rnn:\n",
    "            h = torch.zeros(\n",
    "                self.rnn_num_layers, input_ids.shape[0] * slot_dim, self.hidden_dim\n",
    "            ).to(\n",
    "                self.device\n",
    "            )  # [1, slot_dim*ds, hidden]\n",
    "        else:\n",
    "            h = hidden[:, 0, :].unsqueeze(0).expand(self.rnn_num_layers, -1, -1) # 원래 repeat(self.rnn_num_layers, 1, 1) 이었는데 바꿈\n",
    "            h = self.rnn_init_linear(h)    # 왜냐면 1 dim은 언제나 사이즈 1이니까 expand 사용하는게 더 좋음(expand 메모리 복사 없음, repeat 복사됨)\n",
    "\n",
    "        if isinstance(self.nbt, nn.GRU):\n",
    "            rnn_out, _ = self.nbt(hidden, h)  # [J*B, M, H_GRU]\n",
    "        elif isinstance(self.nbt, nn.LSTM):\n",
    "            c = torch.zeros(\n",
    "                self.rnn_num_layers, input_ids.shape[0] * slot_dim, self.hidden_dim\n",
    "            ).to(\n",
    "                self.device\n",
    "            )  # [1, slot_dim*ds, hidden]\n",
    "            rnn_out, _ = self.nbt(hidden, (h, c))  # [slot_dim*ds, turn, hidden]\n",
    "        rnn_out = self.layer_norm(self.linear(self.dropout(rnn_out)))\n",
    "\n",
    "        hidden = rnn_out.view(slot_dim, ds, ts, -1)  # [J, B, M, H]  변경 전 # [J, B, M, H_G]\n",
    "\n",
    "        # Label (slot-value) encoding\n",
    "        loss = 0\n",
    "        loss_slot = []\n",
    "        pred_slot = []\n",
    "        output = []\n",
    "        for s, slot_id in enumerate(target_slot):  ## note: target_slots are successive\n",
    "            # loss calculation\n",
    "            hid_label = self.value_lookup[slot_id].weight\n",
    "            num_slot_labels = hid_label.size(0)\n",
    "\n",
    "            _hid_label = (\n",
    "                hid_label.unsqueeze(0)\n",
    "                .unsqueeze(0)\n",
    "               .repeat(ds, ts, 1, 1)\n",
    "                .view(ds * ts * num_slot_labels, -1)\n",
    "            )\n",
    "            _hidden = (\n",
    "                hidden[s, :, :, :]\n",
    "                .unsqueeze(2)\n",
    "                .repeat(1, 1, num_slot_labels, 1)\n",
    "                .view(ds * ts * num_slot_labels, -1)\n",
    "            )\n",
    "            _dist = self.metric(_hid_label, _hidden).view(ds, ts, num_slot_labels)\n",
    "            _dist = -_dist\n",
    "            _, pred = torch.max(_dist, -1)\n",
    "            pred_slot.append(pred.view(ds, ts, 1))\n",
    "            output.append(_dist)\n",
    "\n",
    "            if labels is not None:\n",
    "                _loss = self.nll(_dist.view(ds * ts, -1), labels[:, :, s].view(-1))\n",
    "                loss_slot.append(_loss.item())\n",
    "                loss += _loss\n",
    "\n",
    "        pred_slot = torch.cat(pred_slot, 2)\n",
    "        \n",
    "        if labels is None:\n",
    "            return output, pred_slot\n",
    "\n",
    "        # calculate joint accuracy\n",
    "        accuracy = (pred_slot == labels).view(-1, slot_dim)\n",
    "        acc_slot = (\n",
    "            torch.sum(accuracy, 0).float()\n",
    "            / torch.sum(labels.view(-1, slot_dim) > -1, 0).float()\n",
    "        )\n",
    "        acc = (\n",
    "            sum(torch.sum(accuracy, 1) / slot_dim).float()\n",
    "            / torch.sum(labels[:, :, 0].view(-1) > -1, 0).float()\n",
    "        )  # joint accuracy\n",
    "        \n",
    "#         acc2 = ( # 별 차이 없으니까 그냥 기존거 쓰자\n",
    "#             torch.sum(accuracy).float()\n",
    "#             / torch.sum(labels > -1).float()\n",
    "#         )  # joint accuracy\n",
    "#         assert acc == acc2, f'acc: {acc}  acc2: {acc2}'\n",
    "\n",
    "        if n_gpu == 1:\n",
    "            return loss, loss_slot, acc, acc_slot, pred_slot\n",
    "        else:\n",
    "            return (\n",
    "                loss.unsqueeze(0),\n",
    "                None,\n",
    "                acc.unsqueeze(0),\n",
    "                acc_slot.unsqueeze(0),\n",
    "                pred_slot.unsqueeze(0),\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def init_parameter(module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_normal_(module.weight)\n",
    "            torch.nn.init.constant_(module.bias, 0.0)\n",
    "        elif isinstance(module, nn.GRU) or isinstance(module, nn.LSTM):\n",
    "            torch.nn.init.xavier_normal_(module.weight_ih_l0)\n",
    "            torch.nn.init.xavier_normal_(module.weight_hh_l0)\n",
    "            torch.nn.init.constant_(module.bias_ih_l0, 0.0)\n",
    "            torch.nn.init.constant_(module.bias_hh_l0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91624846-fb62-4022-bbea-d2fdcfad8787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def tokenize_ontology(ontology, tokenizer, max_seq_length):\n",
    "    slot_types = []\n",
    "    slot_values = []\n",
    "    for k, v in ontology.items():\n",
    "        tokens = tokenizer.encode(k)\n",
    "        if len(tokens) < max_seq_length:\n",
    "            gap = max_seq_length - len(tokens)\n",
    "            tokens.extend([tokenizer.pad_token_id] * gap)\n",
    "        slot_types.append(tokens)\n",
    "        slot_value = []\n",
    "        for vv in v:\n",
    "            tokens = tokenizer.encode(vv)\n",
    "            if len(tokens) < max_seq_length:\n",
    "                gap = max_seq_length - len(tokens)\n",
    "                tokens.extend([tokenizer.pad_token_id] * gap)\n",
    "            slot_value.append(tokens)\n",
    "        slot_values.append(torch.LongTensor(slot_value))\n",
    "    return torch.LongTensor(slot_types), slot_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7bcb68f-465d-4336-9fe9-365b72eeaf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Slot:  torch.Size([45, 12])\n",
      "Tokenized Value of 관광-경치 좋은 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-교육적 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-도보 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-문화 예술 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-역사적 torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "slot_type_ids, slot_values_ids = tokenize_ontology(ontology, tokenizer, 12)\n",
    "num_labels = [len(s) for s in slot_values_ids]\n",
    "\n",
    "print('Tokenized Slot: ', slot_type_ids.size())\n",
    "cnt = 0\n",
    "for slot, slot_value_id in zip(slot_meta, slot_values_ids):\n",
    "    print(f'Tokenized Value of {slot}', slot_value_id.size())\n",
    "    cnt += 1\n",
    "    if cnt > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a83fce2e-9f50-4ccf-9727-32a71858c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = [len(s) for s in slot_values_ids]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_gpu = 1 if torch.cuda.device_count() < 2 else torch.cuda.device_count()\n",
    "n_epochs = args.num_train_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5c7e879-4dbd-48f6-ae88-f6d3218a9f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete initialization of slot and value lookup\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "model = SUMBT(args, num_labels, device)\n",
    "model.initialize_slot_value_lookup(slot_values_ids, slot_type_ids)  # Tokenized Ontology의 Pre-encoding using BERT_SV\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a0c0daa-abe2-4703-a987-791dde28b357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45, 768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.slot_lookup.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "131235ff-b27a-4863-86f2-07e1f3a6d4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45, 12])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slot_type_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1abd0a19-6cc2-4edf-9d01-3ad5a3cf2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import WOSDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import random\n",
    "\n",
    "\n",
    "train_data = WOSDataset(train_features)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(train_data, batch_size=8, sampler=train_sampler, collate_fn=processor.collate_fn)\n",
    "\n",
    "dev_data = WOSDataset(dev_features)\n",
    "dev_sampler = SequentialSampler(dev_data)\n",
    "dev_loader = DataLoader(dev_data, batch_size=8, sampler=dev_sampler, collate_fn=processor.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0aaf7dda-5cd8-4421-ae9e-07e6bab37a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "t_total = len(train_loader) * n_epochs\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=int(t_total * args.warmup_ratio), num_training_steps=t_total\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9dff834-09d3-42ab-9bcc-b9736a7fc516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import _evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0eb8f58-45dc-4d9e-bb20-3694ade6ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, eval_loader, processor, device):\n",
    "    model.eval()\n",
    "    predictions = {}\n",
    "    \n",
    "    for step, batch in tqdm(enumerate(eval_loader), total=len(eval_loader)):\n",
    "        input_ids, segment_ids, input_masks, target_ids, num_turns, guids  = \\\n",
    "            [b.to(device) if not isinstance(b, list) else b for b in batch]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            with autocast(enabled=use_amp):\n",
    "                output, pred_slot = model(input_ids, segment_ids, input_masks, None, 1)\n",
    "            \n",
    "        pred_slot = pred_slot.detach().cpu()\n",
    "        \n",
    "        for guid, num_turn, p_slot in zip(guids, num_turns, pred_slot):\n",
    "            pred_states = processor.recover_state(p_slot, num_turn)\n",
    "            for t_idx, pred_state in enumerate(pred_states):\n",
    "                predictions[f'{guid}-{t_idx}'] = pred_state\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a76acc85-ce63-49c1-bbb3-f6ebb2de64a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac031a5ce5544c82bfde7425952a5621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea6ede6fb2f43989aef5c4c2c396199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=788.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10] [0/788] 110.114372\n",
      "[0/10] [100/788] 42.105022\n",
      "[0/10] [200/788] 40.169041\n",
      "[0/10] [300/788] 31.595776\n",
      "[0/10] [400/788] 32.986732\n",
      "[0/10] [500/788] 30.214699\n",
      "[0/10] [600/788] 23.632011\n",
      "[0/10] [700/788] 23.125034\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b15c1c08dc482bae2270f2c8b50dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'joint_goal_accuracy': 0.024, 'turn_slot_accuracy': 0.8592622222222255, 'turn_slot_f1': 0.25224322985130887}\n",
      "joint_goal_accuracy: 0.024\n",
      "turn_slot_accuracy: 0.8592622222222255\n",
      "turn_slot_f1: 0.25224322985130887\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6bb2e34a184648b1006522415dbb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=788.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] [0/788] 17.328161\n",
      "[1/10] [100/788] 20.273682\n",
      "[1/10] [200/788] 16.353893\n",
      "[1/10] [300/788] 17.911474\n",
      "[1/10] [400/788] 14.494902\n",
      "[1/10] [500/788] 17.318621\n",
      "[1/10] [600/788] 15.776504\n",
      "[1/10] [700/788] 14.748581\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fcfd8ddee740398f6f235c3f52fe80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'joint_goal_accuracy': 0.2174, 'turn_slot_accuracy': 0.9455111111111172, 'turn_slot_f1': 0.753052711805542}\n",
      "joint_goal_accuracy: 0.2174\n",
      "turn_slot_accuracy: 0.9455111111111172\n",
      "turn_slot_f1: 0.753052711805542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d23173ebf64a66990a6db4c1d8d518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=788.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/10] [0/788] 8.080420\n",
      "[2/10] [100/788] 12.932704\n",
      "[2/10] [200/788] 9.851366\n",
      "[2/10] [300/788] 6.188788\n",
      "[2/10] [400/788] 5.190873\n",
      "[2/10] [500/788] 8.912785\n",
      "[2/10] [600/788] 7.961097\n",
      "[2/10] [700/788] 7.608935\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c87ddeb82c24639a251640f4f4bd815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'joint_goal_accuracy': 0.3406, 'turn_slot_accuracy': 0.967631111111123, 'turn_slot_f1': 0.8578728067574232}\n",
      "joint_goal_accuracy: 0.3406\n",
      "turn_slot_accuracy: 0.967631111111123\n",
      "turn_slot_f1: 0.8578728067574232\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348fa02fdc2e4eb488dafe5ac16b022b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=788.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/10] [0/788] 5.408825\n",
      "[3/10] [100/788] 9.172296\n",
      "[3/10] [200/788] 7.001889\n",
      "[3/10] [300/788] 5.341996\n",
      "[3/10] [400/788] 5.472009\n",
      "[3/10] [500/788] 5.363335\n",
      "[3/10] [600/788] 5.499571\n",
      "[3/10] [700/788] 5.060927\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4db6d234174dc1a62ba4994b8beac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'joint_goal_accuracy': 0.517, 'turn_slot_accuracy': 0.9791155555555675, 'turn_slot_f1': 0.9096544303770001}\n",
      "joint_goal_accuracy: 0.517\n",
      "turn_slot_accuracy: 0.9791155555555675\n",
      "turn_slot_f1: 0.9096544303770001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7503bf2ff0474da2ad9f215d3e8cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=788.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/10] [0/788] 6.880244\n",
      "[4/10] [100/788] 3.741772\n",
      "[4/10] [200/788] 4.186904\n",
      "[4/10] [300/788] 3.017449\n",
      "[4/10] [400/788] 3.975590\n",
      "[4/10] [500/788] 4.952283\n",
      "[4/10] [600/788] 2.533686\n",
      "[4/10] [700/788] 3.052412\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a703d59507456c812c39e966684b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'joint_goal_accuracy': 0.6318, 'turn_slot_accuracy': 0.9858222222222277, 'turn_slot_f1': 0.9438924433622662}\n",
      "joint_goal_accuracy: 0.6318\n",
      "turn_slot_accuracy: 0.9858222222222277\n",
      "turn_slot_f1: 0.9438924433622662\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab89259bb4a4310b83c900ed0cd3e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=788.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/10] [0/788] 3.120384\n",
      "[5/10] [100/788] 2.730460\n",
      "[5/10] [200/788] 2.772091\n",
      "[5/10] [300/788] 2.292273\n",
      "[5/10] [400/788] 3.908187\n",
      "[5/10] [500/788] 2.580435\n",
      "[5/10] [600/788] 2.673415\n",
      "[5/10] [700/788] 2.385585\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb1921de7e94c23ae25f630a623190a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'joint_goal_accuracy': 0.6976, 'turn_slot_accuracy': 0.9888711111111154, 'turn_slot_f1': 0.9592945034493471}\n",
      "joint_goal_accuracy: 0.6976\n",
      "turn_slot_accuracy: 0.9888711111111154\n",
      "turn_slot_f1: 0.9592945034493471\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac90d6b8c0c4ceeb60c84b7a7f00696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=788.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/10] [0/788] 3.162676\n",
      "[6/10] [100/788] 3.083665\n",
      "[6/10] [200/788] 2.676375\n",
      "[6/10] [300/788] 2.634556\n",
      "[6/10] [400/788] 2.259705\n",
      "[6/10] [500/788] 1.820995\n",
      "[6/10] [600/788] 2.364776\n",
      "[6/10] [700/788] 3.101809\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b07704e98cb474989239eda4e8f4763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'joint_goal_accuracy': 0.7046, 'turn_slot_accuracy': 0.9894888888888932, 'turn_slot_f1': 0.9616417469885348}\n",
      "joint_goal_accuracy: 0.7046\n",
      "turn_slot_accuracy: 0.9894888888888932\n",
      "turn_slot_f1: 0.9616417469885348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ad0982366541db80d857e59bc59c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=788.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/10] [0/788] 3.353815\n",
      "[7/10] [100/788] 2.754048\n",
      "[7/10] [200/788] 2.454591\n",
      "[7/10] [300/788] 1.503506\n",
      "[7/10] [400/788] 1.847074\n",
      "[7/10] [500/788] 2.197183\n",
      "[7/10] [600/788] 1.876140\n",
      "[7/10] [700/788] 1.999339\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e011051c791d4c3d8086198797496a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'joint_goal_accuracy': 0.7136, 'turn_slot_accuracy': 0.9899422222222276, 'turn_slot_f1': 0.9633212478024045}\n",
      "joint_goal_accuracy: 0.7136\n",
      "turn_slot_accuracy: 0.9899422222222276\n",
      "turn_slot_f1: 0.9633212478024045\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce36738094944d6cb3e1060a42793aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=788.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/10] [0/788] 1.431324\n",
      "[8/10] [100/788] 1.548443\n",
      "[8/10] [200/788] 1.633593\n",
      "[8/10] [300/788] 0.862671\n",
      "[8/10] [400/788] 1.790905\n",
      "[8/10] [500/788] 1.428502\n",
      "[8/10] [600/788] 2.430533\n",
      "[8/10] [700/788] 2.556275\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f137a1a3fb4549b2978e18e23f41ab48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'joint_goal_accuracy': 0.7278, 'turn_slot_accuracy': 0.9904177777777817, 'turn_slot_f1': 0.9651944989870144}\n",
      "joint_goal_accuracy: 0.7278\n",
      "turn_slot_accuracy: 0.9904177777777817\n",
      "turn_slot_f1: 0.9651944989870144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f339327bf4f4c568d2b31935477ba76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=788.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/10] [0/788] 0.735247\n",
      "[9/10] [100/788] 2.006325\n",
      "[9/10] [200/788] 2.043746\n",
      "[9/10] [300/788] 1.890898\n",
      "[9/10] [400/788] 0.950637\n",
      "[9/10] [500/788] 1.352677\n",
      "[9/10] [600/788] 2.410396\n",
      "[9/10] [700/788] 2.371645\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b98f45ff68474cbfe7ec55382cbb87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'joint_goal_accuracy': 0.7312, 'turn_slot_accuracy': 0.9906177777777823, 'turn_slot_f1': 0.9658299304072602}\n",
      "joint_goal_accuracy: 0.7312\n",
      "turn_slot_accuracy: 0.9906177777777823\n",
      "turn_slot_f1: 0.9658299304072602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "best_score, best_checkpoint = 0, 0\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    batch_loss = []\n",
    "    model.train()\n",
    "    for step, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids, segment_ids, input_masks, target_ids, num_turns, guids  = \\\n",
    "        [b.to(device) if not isinstance(b, list) else b for b in batch]\n",
    "\n",
    "        # Forward\n",
    "        with autocast(enabled=use_amp):\n",
    "            if n_gpu == 1:\n",
    "                loss, loss_slot, acc, acc_slot, _ = model(input_ids, segment_ids, input_masks, target_ids, n_gpu)\n",
    "            else:\n",
    "                loss, _, acc, acc_slot, _ = model(input_ids, segment_ids, input_masks, target_ids, n_gpu)\n",
    "        \n",
    "        batch_loss.append(loss.item())\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        \n",
    "        scale = scaler.get_scale()\n",
    "        scaler.update()\n",
    "        step_scheduler = scaler.get_scale() == scale\n",
    "        \n",
    "        if step_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print('[%d/%d] [%d/%d] %f' % (epoch, n_epochs, step, len(train_loader), loss.item()))\n",
    "            \n",
    "    predictions = inference(model, dev_loader, processor, device)\n",
    "    eval_result = _evaluation(predictions, dev_labels, slot_meta)\n",
    "    for k, v in eval_result.items():\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "861e93b2-21a5-40d2-a03d-5ac8a7528604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f478c1f2a18b4547af70af9fbd39c079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157a9317f32b455d8745e0282e4eda78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_data = json.load(open(f\"/opt/ml/input/data/eval_dataset/eval_dials.json\", \"r\"))\n",
    "\n",
    "eval_examples = get_examples_from_dialogues(\n",
    "    eval_data, user_first=True, dialogue_level=True\n",
    ")\n",
    "\n",
    "# Extracting Featrues\n",
    "eval_features = processor.convert_examples_to_features(eval_examples)\n",
    "eval_data = WOSDataset(eval_features)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_loader = DataLoader(\n",
    "    eval_data,\n",
    "    batch_size=8,\n",
    "    sampler=eval_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ff35616-a61d-4372-88e0-2272c8b6f01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1467f912b4a24bbca7322a02da79b66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = inference(model, eval_loader, processor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a7a6a91-639c-4586-9d59-49a858244f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(predictions, open('predictions/koelectra_base.csv', 'w'), indent=2, ensure_ascii=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc2f11a-7342-412e-b125-6cf7cf053ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
