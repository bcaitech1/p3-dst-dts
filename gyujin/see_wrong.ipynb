{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "c67fd2b5-d937-43d5-a3c4-8e0863a2442e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\t     data_utils.py  new_trade\t      sweep.yml\n",
      "__pycache__\t     dec_trade\t    old_trade\t      train.py\n",
      "base_config.yml      eda.py\t    parser_maker.py   train_copy.py\n",
      "chan_cur\t     etc\t    predictions       train_inference.py\n",
      "chan_wd\t\t     eval_utils.py  prepare.py\t      train_loop.py\n",
      "change_ont_value.py  evaluation.py  preprocessor      training_recorder.py\n",
      "conf.yml\t     graph\t    requirements.txt  wandb\n",
      "conf2.yml\t     inference.py   results\t      wandb_stuff.py\n",
      "conf3.yml\t     losses.py\t    small_trade       whole-in-one.py\n",
      "configs\t\t     model\t    submit.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ef7878e-fd96-4277-a52d-def1d2778813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/project/team/code\n"
     ]
    }
   ],
   "source": [
    "%cd ~/project/team/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58f8202d-9515-4b72-9f2a-7933881560cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import (WOSDataset, load_dataset,\n",
    "                        seed_everything)\n",
    "from evaluation import _evaluation\n",
    "\n",
    "from train_loop import trade_train_loop, submt_train_loop\n",
    "from inference import trade_inference, sumbt_inference \n",
    "\n",
    "from prepare import get_data, get_stuff, get_model\n",
    "\n",
    "from attrdict import AttrDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e141d234-5a79-4459-8f9d-ce46a8b89f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = AttrDict(\n",
    "    data_dir= '/opt/ml/input/data/train_dataset',\n",
    "    ontology_root='/opt/ml/input/data/train_dataset/edit_ontology_metro.json',\n",
    "    use_domain_slot='basic',\n",
    "    \n",
    "    use_small_data=False,\n",
    "    train_batch_size=8,\n",
    "    model_name_or_path= 'dsksd/bert-ko-small-minimal',\n",
    "    vocab_size=35000,\n",
    "    preprocessor='TRADEPreprocessor',\n",
    "    model_class='TRADE',\n",
    "    ModelName='TRADE',\n",
    "    use_convert_ont=False,\n",
    "    use_sys_usr_sys_turn=False,\n",
    ")\n",
    "\n",
    "model_folder = 'results/decoder_long/'\n",
    "model_name = 'model-best.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "998ed4a3-b1d3-4ee6-bb8b-4d68f5cac55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, slot_meta, ontology = get_data(args)\n",
    "train_data, dev_data, _, _ = load_dataset(data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88b246-da73-4544-bfaf-f2a01063baca",
   "metadata": {},
   "source": [
    "## 둘 중 하나 고르세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4eeaae0-96bd-448c-b41e-fad82bd9e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_domain(data, domain):\n",
    "    found_idx = set()\n",
    "    for i in range(len(data)):\n",
    "        if domain in data[i]['domains']:\n",
    "            found_idx.add(i)\n",
    "    return [data[i] for i in found_idx]\n",
    "\n",
    "domain = '지하철'\n",
    "small_data = filter_by_domain(train_data, domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73509a35-54db-421f-8ba4-c958130fa324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_value(data, target):\n",
    "    found_idx = set()\n",
    "    for i in range(len(data)):\n",
    "        find_next = False\n",
    "        for dig in data[i]['dialogue']:\n",
    "            if 'state' in dig:\n",
    "                for st in dig['state']:\n",
    "                    domain, slot, value =  st.split('-')\n",
    "                    if value == target:\n",
    "                        find_next = True\n",
    "                        found_idx.add(i)\n",
    "                        break\n",
    "            if find_next:\n",
    "                break\n",
    "    return [data[i] for i in found_idx]\n",
    "\n",
    "target = '강남역'\n",
    "small_data = filter_by_value(train_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f197a2d-8a96-42d4-a186-8c36b757c010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e08a256feea4bd0905b4d4ee5cba3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Getting train examples from dialogues', max=112.0, style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1784781075042de804a971996d28685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Converting train examples to features', max=820.0, style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer, processor, train_features, dev_features = get_stuff(args,\n",
    "                 small_data, None, slot_meta, ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1dc3d22-c635-4c38-b955-ec2cd0d38bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89343c15a9a4cd2b14059511137c23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Making TRADE model -- waiting...', max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "\n",
    "\n",
    "\n",
    "tokenized_slot_meta = []\n",
    "for slot in slot_meta:\n",
    "    tokenized_slot_meta.append(\n",
    "        tokenizer.encode(slot.replace(\"-\", \" \"), add_special_tokens=False)\n",
    "    )\n",
    "config = json.load(open(f\"{model_folder}/exp_config.json\", \"r\"))\n",
    "config = argparse.Namespace(**config)\n",
    "model =  get_model(config, tokenizer, ontology, slot_meta)\n",
    "ckpt = torch.load(f'{model_folder}/{model_name}', map_location=\"cpu\")\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "train_data2 = WOSDataset(train_features)\n",
    "train_sampler = SequentialSampler(train_data2)\n",
    "train_loader = DataLoader(\n",
    "    train_data2,\n",
    "    batch_size=args.train_batch_size,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a432783b-f961-4c6f-8e7c-eb171769f975",
   "metadata": {},
   "source": [
    "## 일단 TRADE 모델 꺼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a47ddaf-fe8a-4132-8480-2a5ae0a3c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_state(state):\n",
    "    for i, s in enumerate(state):\n",
    "        s = s.replace(\" : \", \":\")\n",
    "        s = s.replace(\" & \", \"&\")\n",
    "        s = s.replace(\" = \", \"=\")\n",
    "        s = s.replace(\"( \", \"(\")\n",
    "        s = s.replace(\" )\", \")\")\n",
    "        state[i] = s.replace(\" , \", \", \")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3a606358-77c2-4924-bac9-796744bdaad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu') # 개인 사정에 맞게 (cpu | cuda)\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529eea12-f712-49bb-a2ba-013d31d626e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6056edebc4e1485a876ac688cc9f8b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=103.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from training_recorder import RunningLossRecorder\n",
    "from torch.cuda.amp import autocast\n",
    "use_amp = False\n",
    "\n",
    "model.eval()\n",
    "predictions = {}\n",
    "no_post = {}\n",
    "eval_loader = train_loader\n",
    "pbar = tqdm(eval_loader, total=len(eval_loader))\n",
    "loss_recorder = RunningLossRecorder(len(eval_loader))\n",
    "cnt = 0\n",
    "for batch in pbar:\n",
    "    input_ids, segment_ids, input_masks, gating_ids, target_ids, guids = [\n",
    "        b.to(torch.device(device)) if not isinstance(b, list) else b for b in batch\n",
    "    ]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with autocast(enabled=use_amp):\n",
    "            o, g = model(input_ids, segment_ids, input_masks, 9)\n",
    "\n",
    "        _, generated_ids = o.max(-1)\n",
    "        _, gated_ids = g.max(-1)\n",
    "\n",
    "\n",
    "    for guid, gate, gen in zip(guids, gated_ids.tolist(), generated_ids.tolist()):\n",
    "        prediction = processor.recover_state(gate, gen)\n",
    "        no_post[guid] = prediction\n",
    "        prediction = postprocess_state(prediction)\n",
    "        predictions[guid] = prediction\n",
    "\n",
    "    cnt += 1\n",
    "#     if cnt == 1:\n",
    "#         break\n",
    "    \n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "207e5a6d-2963-4958-855a-383dc3369969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e0e3bcaaf74ad1a2ace92cea55f720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Getting train examples from dialogues', max=112.0, style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from data_utils import get_examples_from_dialogues\n",
    "user_first = False\n",
    "dialogue_level = False\n",
    "processor_kwargs = AttrDict()\n",
    "    \n",
    "train_examples = get_examples_from_dialogues(\n",
    "    small_data, user_first=user_first, dialogue_level=dialogue_level,use_sys_usr_sys=args.use_sys_usr_sys_turn,\n",
    "        which='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deea92d-ebf6-4ec4-85ff-3926240106a8",
   "metadata": {},
   "source": [
    "## 보는 방법은 CONTROL + ENTER로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf66cd88-e28f-4460-b09e-58981432af3c",
   "metadata": {},
   "source": [
    "* MISSED: 정답인데 예측 하지 않은 거\n",
    "*  WRONG: 예측한 값이 틀린 경우\n",
    "* CORREC: 제대로 예측한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1a77eae-275b-4846-bde4-ba2a5fec06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "ln = len(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5605907b-2b4b-48c3-abcd-a9d67443e883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialogue 30\n",
      "SYS: \n",
      "USR: 서울 남쪽으로 비싼 가격대의 식당을 찾고있어요. \n",
      "SYS: 안녕하세요. 식당의 종류는 어떻게 도와드릴까요? \n",
      "USR: 종류는 아무거나 괜찮아요. \n",
      "SYS: 팁 앤 스테이크 어떠세요? 평점은 3.8 입니다. \n",
      "USR: 대표 메뉴 알려주세요. 예약도 해주시고요. 토요일에 20시 3명이요. \n",
      "SYS: 예약 번호는 OIFM2 입니다. 대표 메뉴는 스테이크입니다. \n",
      "USR: 아 그리고 가까운 지하철역 알려주세요. \n",
      "SYS: 강남역으로 나옵니다. \n",
      "USR: 감사합니다. 숙소도 알아봐주시겠어요? 조식 제공되는 적당한 가격대의 숙소로요. \n",
      "\n",
      "SYS: 숙소의 종류와 지역은 어떻게 할까요? \n",
      "USR: 크게 상관없으니 알아서 해주세요. 가까운 지하철역이 어디인지도 같이 알아봐주세요. \n",
      "SYS: 김의 옥탑방 어떠세요? 평점은 4.5 입니다. 가까운 지하철역은 노원역입니다. \n",
      "\n",
      "MISSED: \n",
      "WRONG : 숙소-이름-김의 옥탑방\n",
      "CORREC: \n",
      "[   '숙소-가격대-적당',\n",
      "    '숙소-조식 가능-yes',\n",
      "    '숙소-종류-dontcare',\n",
      "    '숙소-지역-dontcare',\n",
      "    '식당-가격대-비싼',\n",
      "    '식당-예약 명수-3',\n",
      "    '식당-예약 시간-20:00',\n",
      "    '식당-예약 요일-토요일',\n",
      "    '식당-이름-팁 앤 스테이크',\n",
      "    '식당-종류-dontcare',\n",
      "    '식당-지역-서울 남쪽']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "while idx < ln:\n",
    "    datum = train_examples[idx]\n",
    "    idx += 1\n",
    "    guid = datum.guid\n",
    "    answer = set(datum.label)\n",
    "    pred = set(predictions[guid])\n",
    "    if set(datum.label) != set(predictions[guid]):\n",
    "        print(f'dialogue {idx}')\n",
    "        for i in range(len(datum.context_turns)//2):\n",
    "            print(f'SYS: {datum.context_turns[2*i]}')\n",
    "            print(f'USR: {datum.context_turns[2*i + 1]}')\n",
    "\n",
    "        print()\n",
    "        print(f'SYS: {datum.current_turn[0]}')\n",
    "        print(f'USR: {datum.current_turn[1]}')\n",
    "        if args.use_sys_usr_sys_turn:\n",
    "            print(f'SYS: {datum.current_turn[2]}')\n",
    "        print()\n",
    "        tab = '\\t'\n",
    "        print(f'MISSED: {tab.join(sorted(answer - pred))}')\n",
    "        print(f'WRONG : {tab.join(sorted(pred - answer))}')\n",
    "        print(f'CORREC: ')\n",
    "        pp.pprint(sorted(answer & pred))\n",
    "        break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f2c3a5-3d9c-4fe6-8bfc-4f3102ffe973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
